{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa1fc6f3",
   "metadata": {},
   "source": [
    "# Classificador de Sentiments a Xarxes Socials en Català (CSXSC): Dataset\n",
    "\n",
    "**Author:** Daniel Arias Cámara  \n",
    "**Date:** July 2025  \n",
    "\n",
    "**Description:**  This notebook aims to build a high-quality dataset for fine-tuning the **CSXSC** model. The dataset is constructed by combining trusted data sources, including structured sentiment corpora and translated social media content. Details on data origin and preprocessing steps are provided in the sections below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfd3695",
   "metadata": {},
   "source": [
    "## 1. GuiaCat Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902f794",
   "metadata": {},
   "source": [
    "**Description:** This dataset consists of 5,750 restaurant reviews in Catalan, sourced from the GuiaCat platform. Each review includes individual ratings for service, food, price-quality ratio, and atmosphere, along with an overall average score.\n",
    "\n",
    "**Access:** [projecte-aina/GuiaCat on Hugging Face](https://huggingface.co/datasets/projecte-aina/GuiaCat)\n",
    "\n",
    "**Source:** Aina Project\n",
    "\n",
    "**Notes:**  \n",
    "The dataset is divided into three subsets:  \n",
    "- **Train:** 4,750 rows  \n",
    "- **Validation:** 500 rows  \n",
    "- **Test:** 500 rows  \n",
    "\n",
    "The original fields are: Service, Food, Price-quality, Environment, Avg, Text, and Label.  \n",
    "For our purposes, we retain only the Text and Label fields, discarding the rest.\n",
    "\n",
    "The Label field includes five sentiment categories:  \n",
    "- Molt bo (Very good)  \n",
    "- Bo (Good)  \n",
    "- Regular (Average)  \n",
    "- Dolent (Bad)  \n",
    "- Molt dolent (Very bad)\n",
    "\n",
    "These are grouped into three classes for sentiment classification:  \n",
    "- **Positive:** Molt bo and Bo  \n",
    "- **Neutral:** Regular  \n",
    "- **Negative:** Dolent and Molt dolent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d57d28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/ai/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing 'projecte-aina/GuiaCat'\n",
      "\n",
      "Final Dataset Distribution\n",
      "Total Rows: 5750\n",
      "Distribution: 94.3% Positive, 3.6% Negative, 2.1% Neutral\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from typing import Dict, List\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    from datasets import load_dataset, concatenate_datasets\n",
    "except ImportError:\n",
    "    subprocess.check_call([\"pip\", \"install\", \"-q\", \"pandas\", \"datasets\", \"pyarrow\"])\n",
    "    import pandas as pd\n",
    "    from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "COLUMNS_TO_KEEP: List[str] = [\"text\", \"label\"]\n",
    "DATASET_NAME: str = \"projecte-aina/GuiaCat\"\n",
    "CSV_FILENAME: str = \"guiacat.csv\"\n",
    "\n",
    "def relabel_opinion(opinion: Dict) -> Dict:\n",
    "    label = opinion[\"label\"].lower()\n",
    "    if label in [\"molt bo\", \"bo\"]:\n",
    "        opinion[\"label\"] = \"positive\"\n",
    "    elif label == \"regular\":\n",
    "        opinion[\"label\"] = \"neutral\"\n",
    "    elif label in [\"dolent\", \"molt dolent\"]:\n",
    "        opinion[\"label\"] = \"negative\"\n",
    "    return opinion\n",
    "\n",
    "def process_and_combine_dataset(dataset_name: str) -> pd.DataFrame:\n",
    "    print(f\"Loading and processing '{dataset_name}'\")\n",
    "    raw_dataset = load_dataset(dataset_name)\n",
    "    \n",
    "    processed_splits = []\n",
    "    for split in raw_dataset:\n",
    "        processed_split = raw_dataset[split].map(relabel_opinion)\n",
    "        drop_columns = [col for col in processed_split.column_names if col not in COLUMNS_TO_KEEP]\n",
    "        processed_splits.append(processed_split.remove_columns(drop_columns))\n",
    "    \n",
    "\n",
    "    combined_dataset = concatenate_datasets(processed_splits)\n",
    "    return combined_dataset.to_pandas()\n",
    "\n",
    "\n",
    "guiacat_df = process_and_combine_dataset(DATASET_NAME)\n",
    "guiacat_df.to_csv(CSV_FILENAME, index=False)\n",
    "\n",
    "total_rows = len(guiacat_df)\n",
    "label_dist = guiacat_df['label'].value_counts(normalize=True) * 100\n",
    "\n",
    "positive_pct = label_dist.get('positive', 0)\n",
    "negative_pct = label_dist.get('negative', 0)\n",
    "neutral_pct = label_dist.get('neutral', 0)\n",
    "\n",
    "print(\"\\nFinal Dataset Distribution\")\n",
    "print(\n",
    "    f\"Total Rows: {total_rows}\\n\"\n",
    "    f\"Distribution: {positive_pct:.1f}% Positive, \"\n",
    "    f\"{negative_pct:.1f}% Negative, \"\n",
    "    f\"{neutral_pct:.1f}% Neutral\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6754525",
   "metadata": {},
   "source": [
    "## 2. Catalan Structured Sentiment Analysis (CaSSA) Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1631b602",
   "metadata": {},
   "source": [
    "**Description:** The CaSSA dataset contains 6,400 reviews and forum messages in Catalan, annotated at the fine-grained level with polar expressions. Each text instance is labeled with all the sentiment expressions it contains. For each polar expression, the annotation includes the **expression itself**, the **target** (i.e., the object of the sentiment), and the **source** (i.e., the subject expressing the sentiment). In total, 25,453 polar expressions have been annotated.\n",
    "\n",
    "**Access:** [projecte-aina/CaSSA on Hugging Face](https://huggingface.co/datasets/projecte-aina/CaSSA-catalan-structured-sentiment-analysis)\n",
    "\n",
    "**Source:** Aina Project\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "Each instance in the dataset is a text. For each text, there can be 0 to unlimited polar expressions, which are contained in the \"opinions\" field. Each opinion contains a source, a target, a polar expression, a polarity value and an intensity value.\n",
    "\n",
    "To convert this structured information into a single sentiment label per text, we apply the following strategy:\n",
    "- Count all Positive, Negative, and Neutral polarities per opinion.\n",
    "- Assign the sentiment label based on the dominant polarity.\n",
    "  - If Positive polar expressions are the majority: **Positive**.\n",
    "  - If Negative polar expressions dominate: **Negative**.\n",
    "  - In case of a tie or no polar expressions: **Neutral**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff72189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing 'projecte-aina/CaSSA-catalan-structured-sentiment-analysis'...\n",
      "\n",
      "Final Dataset Distribution\n",
      "Total Rows: 6400\n",
      "Distribution: 64.0% Positive, 9.5% Negative, 26.5% Neutral\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from typing import Dict, List\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    from datasets import load_dataset\n",
    "except ImportError:\n",
    "    subprocess.check_call([\"pip\", \"install\", \"-q\", \"pandas\", \"datasets\", \"pyarrow\"])\n",
    "    import pandas as pd\n",
    "    from datasets import load_dataset\n",
    "\n",
    "DATASET_NAME: str = \"projecte-aina/CaSSA-catalan-structured-sentiment-analysis\"\n",
    "CSV_FILENAME: str = \"cassa.csv\"\n",
    "COLUMNS_TO_KEEP: List[str] = [\"text\", \"label\"]\n",
    "\n",
    "def relabel_from_opinions(item: Dict) -> Dict:\n",
    "    pos = neg = neu = 0\n",
    "    for opinion in item.get(\"opinions\", []):\n",
    "        polarity = (opinion.get(\"Polarity\") or \"\").strip().lower()\n",
    "        if polarity == \"positive\":\n",
    "            pos += 1\n",
    "        elif polarity == \"negative\":\n",
    "            neg += 1\n",
    "        elif polarity == \"neutral\":\n",
    "            neu += 1\n",
    "\n",
    "    if pos > neg and pos > neu:\n",
    "        label = \"positive\"\n",
    "    elif neg > pos and neg > neu:\n",
    "        label = \"negative\"\n",
    "    else:\n",
    "        label = \"neutral\"\n",
    "\n",
    "    return {\"text\": item[\"text\"], \"label\": label}\n",
    "\n",
    "def process_cassa_dataset(dataset_name: str) -> pd.DataFrame:\n",
    "    print(f\"Loading and processing '{dataset_name}'...\")\n",
    "\n",
    "    raw_dataset = load_dataset(dataset_name)[\"train\"]\n",
    "    processed_dataset = raw_dataset.map(relabel_from_opinions)\n",
    "    \n",
    "    drop_columns = [col for col in processed_dataset.column_names if col not in COLUMNS_TO_KEEP]\n",
    "    cleaned_dataset = processed_dataset.remove_columns(drop_columns)\n",
    "    \n",
    "    return cleaned_dataset.to_pandas()\n",
    "\n",
    "cassa_df = process_cassa_dataset(DATASET_NAME)\n",
    "cassa_df.to_csv(CSV_FILENAME, index=False)\n",
    "\n",
    "total_rows = len(cassa_df)\n",
    "label_dist = cassa_df['label'].value_counts(normalize=True) * 100\n",
    "\n",
    "positive_pct = label_dist.get('positive', 0)\n",
    "negative_pct = label_dist.get('negative', 0)\n",
    "neutral_pct = label_dist.get('neutral', 0)\n",
    "\n",
    "print(\"\\nFinal Dataset Distribution\")\n",
    "print(\n",
    "    f\"Total Rows: {total_rows}\\n\"\n",
    "    f\"Distribution: {positive_pct:.1f}% Positive, \"\n",
    "    f\"{negative_pct:.1f}% Negative, \"\n",
    "    f\"{neutral_pct:.1f}% Neutral\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f160c64",
   "metadata": {},
   "source": [
    "## 3. GoEmotions Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0b3514",
   "metadata": {},
   "source": [
    "## GoEmotions Dataset Processing\n",
    "\n",
    "**Description:**  The **GoEmotions** dataset is a large-scale human-annotated corpus of 58k English Reddit comments labeled for 27 emotion categories plus neutral. It was developed by Google AI to support fine-grained sentiment and emotion classification in user-generated content.  \n",
    "Each comment may have one or multiple labels, making it suitable for multilabel classification tasks.\n",
    "\n",
    "**Access:** [Kaggle - GoEmotions Dataset](https://www.kaggle.com/datasets/debarshichanda/goemotions)  \n",
    "**Source:** Google AI  \n",
    "\n",
    "### Notes\n",
    "\n",
    "The GoEmotions dataset includes annotations for 27 fine-grained emotion categories plus a neutral class.  \n",
    "Since each Reddit comment can have multiple emotions, we adopt a two-step mapping strategy to simplify it into three sentiment categories: Positive, Negative, and Neutral.\n",
    "\n",
    "#### **Step 1: Mapping Emotions to Broad Sentiment Groups**\n",
    "\n",
    "- **Positive**: amusement, excitement, joy, love, desire, optimism, caring, pride, admiration, gratitude, relief, approval.  \n",
    "- **Negative**: fear, nervousness, remorse, embarrassment, disappointment, sadness, grief, disgust, anger, annoyance, disapproval.  \n",
    "- **Ambiguous**: realization, surprise, curiosity, confusion.\n",
    "\n",
    "#### **Step 2: Decision Rule for Classification**\n",
    "\n",
    "For each comment, count how many mapped emotions belong to each group and apply:\n",
    "\n",
    "1. **Positive majority**: classify as **Positive**.  \n",
    "2. **Negative majority**: classify as **Negative**.  \n",
    "3. **Tie or no mapped emotions**: classify as **Neutral**.\n",
    "\n",
    "### Translation to Catalan\n",
    "\n",
    "After sentiment classification, all reviews are translated into Catalan using the  \n",
    "[**Aina Project English–Catalan Translator**](https://huggingface.co/projecte-aina/aina-translator-ca-en),  \n",
    "a machine translation model trained specifically for English to Catalan.\n",
    "\n",
    "### Translation Quality Check\n",
    "\n",
    "To ensure translations are high-quality:\n",
    "\n",
    "1. Use the [**Salamandra 7B Instruct**](https://huggingface.co/BSC-LT/salamandra-7b-instruct) model.  \n",
    "   - **Task 1:** Read the translated review and rate the translation quality on a **1–5 scale**,  \n",
    "     considering the informal nature of social media (emojis, slang, grammar errors).  \n",
    "   - **Task 2:** Justify the score, explaining why it was rated that way.\n",
    "\n",
    "2. **Filtering:**  \n",
    "   - Reviews scoring **below 3** are **discarded**.  \n",
    "   - Justifications are logged for transparency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1a5e6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Step 1: Analyzing GoEmotions Dataset\n",
      "\n",
      "- Step 2: Analyzing Base Datasets (cassa.csv + guiacat.csv)\n",
      "Combined base dataset has 12,150 rows. Distribution: {'positive': 9517, 'neutral': 1815, 'negative': 818}\n",
      "\n",
      "Collection Plan:\n",
      "  Collect Positive: 100 rows\n",
      "  Collect Negative: 6,394 rows\n",
      "  Collect Neutral: 5,397 rows\n",
      "Initializing all models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 102717.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - AINA translator initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/ai/lib/python3.13/site-packages/accelerate/utils/modeling.py:1582: UserWarning: Current model requires 128 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Salamandra evaluator LLM initialized.\n",
      "\n",
      "- Step 3: Collecting and Translating from GoEmotions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting samples:   0%|          | 0/11891 [00:00<?, ?it/s]/tmp/ipykernel_28440/3878026001.py:70: DeprecationWarning: Reading the TranslationResult object as a list of dictionaries is deprecated and will be removed in a future version. Please use the object attributes as described in the documentation: https://opennmt.net/CTranslate2/python/ctranslate2.TranslationResult.html\n",
      "  return sp.decode(translation[0][0][\"tokens\"])\n",
      "Collecting samples: 100%|██████████| 11891/11891 [16:54<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Step 4: Evaluating 500 random translations before saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:   0%|          | 0/500 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   0%|          | 1/500 [01:38<13:36:14, 98.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   0%|          | 2/500 [03:06<12:44:40, 92.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   1%|          | 3/500 [04:34<12:30:08, 90.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   1%|          | 4/500 [08:12<19:24:15, 140.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Tose dm de cvs igual que delsym\n",
      "Reason: La traducció automàtica d'aquesta frase anglesa \"Tose dm de cvs igual que delsym\" ha estat considerada de mala qualitat perquè conté errors gramaticals i ortogràfics. Concretament, hi ha faltes d'ortografia com ara la paraula 'dm', que hauria de ser 'damage'. També hi ha un error gramatical en l'estructura de les frases, ja que algunes paraules estan mal col·locades o utilitzades incorrectament. Per exemple, la paraula\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:   1%|          | 5/500 [09:32<16:19:22, 118.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   1%|          | 6/500 [10:42<14:01:50, 102.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   1%|▏         | 7/500 [11:54<12:38:34, 92.32s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   2%|▏         | 8/500 [13:07<11:46:18, 86.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   2%|▏         | 9/500 [14:18<11:06:55, 81.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   2%|▏         | 10/500 [15:28<10:36:07, 77.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   2%|▏         | 11/500 [16:37<10:13:26, 75.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   2%|▏         | 12/500 [17:49<10:02:33, 74.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   3%|▎         | 13/500 [19:02<9:58:56, 73.79s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   3%|▎         | 14/500 [20:15<9:55:50, 73.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   3%|▎         | 15/500 [21:25<9:46:18, 72.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   3%|▎         | 16/500 [22:32<9:32:25, 70.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   3%|▎         | 17/500 [23:40<9:23:52, 70.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   4%|▎         | 18/500 [24:47<9:16:01, 69.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   4%|▍         | 19/500 [25:59<9:20:27, 69.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   4%|▍         | 20/500 [27:06<9:12:44, 69.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   4%|▍         | 21/500 [28:14<9:07:56, 68.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   4%|▍         | 22/500 [29:23<9:07:53, 68.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   5%|▍         | 23/500 [30:31<9:06:25, 68.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   5%|▍         | 24/500 [31:39<9:01:40, 68.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   5%|▌         | 25/500 [32:47<9:01:44, 68.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   5%|▌         | 26/500 [33:58<9:05:17, 69.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   5%|▌         | 27/500 [35:08<9:07:42, 69.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   6%|▌         | 28/500 [36:17<9:04:14, 69.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   6%|▌         | 29/500 [37:30<9:12:39, 70.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   6%|▌         | 30/500 [38:39<9:08:52, 70.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   6%|▌         | 31/500 [39:50<9:08:49, 70.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   6%|▋         | 32/500 [40:57<9:01:10, 69.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   7%|▋         | 33/500 [42:03<8:52:18, 68.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   7%|▋         | 34/500 [43:15<8:59:28, 69.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   7%|▋         | 35/500 [44:23<8:54:10, 68.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   7%|▋         | 36/500 [45:30<8:48:22, 68.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   7%|▋         | 37/500 [46:41<8:53:40, 69.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   8%|▊         | 38/500 [47:48<8:48:30, 68.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   8%|▊         | 39/500 [48:58<8:49:23, 68.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   8%|▊         | 40/500 [50:11<8:57:04, 70.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   8%|▊         | 41/500 [51:26<9:08:50, 71.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   8%|▊         | 42/500 [52:36<9:02:24, 71.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   9%|▊         | 43/500 [53:46<8:58:18, 70.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   9%|▉         | 44/500 [54:58<9:00:14, 71.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   9%|▉         | 45/500 [56:06<8:53:46, 70.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   9%|▉         | 46/500 [57:19<8:56:28, 70.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:   9%|▉         | 47/500 [58:29<8:53:30, 70.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  10%|▉         | 48/500 [59:39<8:52:28, 70.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  10%|▉         | 49/500 [1:00:46<8:42:42, 69.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  10%|█         | 50/500 [1:01:58<8:46:40, 70.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  10%|█         | 51/500 [1:03:11<8:50:55, 70.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  10%|█         | 52/500 [1:04:17<8:40:09, 69.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  11%|█         | 53/500 [1:05:26<8:36:04, 69.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  11%|█         | 54/500 [1:06:39<8:42:59, 70.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  11%|█         | 55/500 [1:07:47<8:38:21, 69.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  11%|█         | 56/500 [1:08:57<8:35:55, 69.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  11%|█▏        | 57/500 [1:10:04<8:28:12, 68.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  12%|█▏        | 58/500 [1:11:15<8:32:29, 69.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  12%|█▏        | 59/500 [1:12:26<8:34:21, 69.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  12%|█▏        | 60/500 [1:13:32<8:25:36, 68.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  12%|█▏        | 61/500 [1:14:41<8:23:45, 68.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  12%|█▏        | 62/500 [1:15:49<8:21:29, 68.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  13%|█▎        | 63/500 [1:16:57<8:18:26, 68.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  13%|█▎        | 64/500 [1:18:05<8:15:35, 68.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  13%|█▎        | 65/500 [1:19:15<8:19:27, 68.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  13%|█▎        | 66/500 [1:20:23<8:16:51, 68.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  13%|█▎        | 67/500 [1:23:09<11:45:14, 97.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Fa massa fred per sortir al carrer la major part de l'any. Plorar per les càmeres web és tot el que tenen!\n",
      "Reason: La frase \"Fa massa fred per sortir al carrer la major part de l'any\" probablement es refereix a un país d'Europa continental o Àsia del Nord, mentre que \"Plorar per les càmeres web\" sembla referir-se als Estats Units. Això fa pensar que hi ha hagut algun tipus de malentès durant la traducció.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  14%|█▎        | 68/500 [1:24:16<10:36:30, 88.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  14%|█▍        | 69/500 [1:25:24<9:51:08, 82.29s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  14%|█▍        | 70/500 [1:26:31<9:18:33, 77.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  14%|█▍        | 71/500 [1:27:46<9:09:12, 76.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  14%|█▍        | 72/500 [1:28:53<8:47:51, 74.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  15%|█▍        | 73/500 [1:30:03<8:37:30, 72.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  15%|█▍        | 74/500 [1:32:57<12:12:51, 103.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Tria'n una. - El socialisme no pot treballar la gent la naturalesa humana és intrínsecament egoista. - No necessitem impostos perquè la gent serà naturalment caritativa.\n",
      "Reason: La primera frase conté un error gramatical; hauria d'\"intrinsicament\" en comptes d'\"intrínsecament\". L'altra frase es basa en l'error que les persones són inherentment generoses sense necessitat d'impostos. Aquestes frases podrien haver estat escrites per algú que no parla bé el català o que té coneixements limitats sobre economia política.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  15%|█▌        | 75/500 [1:34:07<11:00:10, 93.20s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  15%|█▌        | 76/500 [1:35:20<10:15:31, 87.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  15%|█▌        | 77/500 [1:36:32<9:43:13, 82.73s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  16%|█▌        | 78/500 [1:37:42<9:14:04, 78.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  16%|█▌        | 79/500 [1:38:50<8:49:15, 75.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  16%|█▌        | 80/500 [1:39:59<8:35:03, 73.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  16%|█▌        | 81/500 [1:41:08<8:23:43, 72.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  16%|█▋        | 82/500 [1:42:15<8:13:08, 70.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  17%|█▋        | 83/500 [1:43:27<8:13:24, 70.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  17%|█▋        | 84/500 [1:44:37<8:11:51, 70.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  17%|█▋        | 85/500 [1:45:51<8:15:19, 71.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  17%|█▋        | 86/500 [1:47:03<8:15:54, 71.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  17%|█▋        | 87/500 [1:48:12<8:08:27, 70.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  18%|█▊        | 88/500 [1:49:18<7:57:18, 69.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  18%|█▊        | 89/500 [1:50:27<7:54:35, 69.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  18%|█▊        | 90/500 [1:51:38<7:57:15, 69.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  18%|█▊        | 91/500 [1:52:46<7:53:04, 69.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  18%|█▊        | 92/500 [1:53:56<7:51:57, 69.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  19%|█▊        | 93/500 [1:55:03<7:47:03, 68.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  19%|█▉        | 94/500 [1:56:11<7:43:44, 68.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  19%|█▉        | 95/500 [1:57:22<7:46:16, 69.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  19%|█▉        | 96/500 [1:58:31<7:46:40, 69.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  19%|█▉        | 97/500 [1:59:41<7:47:08, 69.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  20%|█▉        | 98/500 [2:00:52<7:47:40, 69.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  20%|█▉        | 99/500 [2:01:59<7:40:59, 68.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  20%|██        | 100/500 [2:03:10<7:43:40, 69.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  20%|██        | 101/500 [2:04:21<7:46:30, 70.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  20%|██        | 102/500 [2:05:28<7:38:58, 69.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  21%|██        | 103/500 [2:06:39<7:41:02, 69.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  21%|██        | 104/500 [2:07:49<7:41:04, 69.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  21%|██        | 105/500 [2:08:59<7:39:03, 69.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  21%|██        | 106/500 [2:10:08<7:35:55, 69.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  21%|██▏       | 107/500 [2:11:19<7:37:52, 69.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  22%|██▏       | 108/500 [2:12:27<7:33:12, 69.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  22%|██▏       | 109/500 [2:13:37<7:33:00, 69.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  22%|██▏       | 110/500 [2:14:46<7:31:11, 69.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  22%|██▏       | 111/500 [2:15:57<7:33:39, 69.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  22%|██▏       | 112/500 [2:17:07<7:33:09, 70.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  23%|██▎       | 113/500 [2:18:20<7:37:30, 70.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  23%|██▎       | 114/500 [2:19:30<7:34:33, 70.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  23%|██▎       | 115/500 [2:20:39<7:29:52, 70.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  23%|██▎       | 116/500 [2:21:48<7:26:21, 69.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  23%|██▎       | 117/500 [2:23:00<7:29:05, 70.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  24%|██▎       | 118/500 [2:24:07<7:21:52, 69.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  24%|██▍       | 119/500 [2:25:14<7:16:51, 68.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  24%|██▍       | 120/500 [2:26:21<7:12:07, 68.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  24%|██▍       | 121/500 [2:27:32<7:15:18, 68.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  24%|██▍       | 122/500 [2:28:40<7:13:39, 68.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  25%|██▍       | 123/500 [2:29:47<7:07:28, 68.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  25%|██▍       | 124/500 [2:30:58<7:12:04, 68.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  25%|██▌       | 125/500 [2:32:09<7:14:46, 69.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  25%|██▌       | 126/500 [2:33:18<7:13:21, 69.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  25%|██▌       | 127/500 [2:34:26<7:09:53, 69.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  26%|██▌       | 128/500 [2:35:34<7:05:25, 68.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  26%|██▌       | 129/500 [2:36:45<7:09:46, 69.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  26%|██▌       | 130/500 [2:39:06<9:20:40, 90.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: >els dos partits són ximples > tribalisme estúpid  ⁇ \n",
      "Reason: Possible raó de la mala qualitat: l’ús inadequat dels signes d’interrogació i exclamació.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  26%|██▌       | 131/500 [2:40:14<8:35:51, 83.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  26%|██▋       | 132/500 [2:41:24<8:09:19, 79.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  27%|██▋       | 133/500 [2:42:30<7:42:52, 75.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  27%|██▋       | 134/500 [2:43:37<7:26:14, 73.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  27%|██▋       | 135/500 [2:44:48<7:19:52, 72.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  27%|██▋       | 136/500 [2:45:57<7:13:55, 71.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  27%|██▋       | 137/500 [2:47:06<7:08:23, 70.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  28%|██▊       | 138/500 [2:48:13<7:00:05, 69.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  28%|██▊       | 139/500 [2:49:27<7:05:56, 70.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  28%|██▊       | 140/500 [2:51:54<9:23:07, 93.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Típic canal d'escombraries Lebronsexual. No veure vídeo.\n",
      "Reason: Possibles problemes de traducció: \"Típico canal basura Lebronsexual. No ver video.\" -> \"Típic canal escombraria Lebronsexual. No mirar vídeo.\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  28%|██▊       | 141/500 [2:53:03<8:35:25, 86.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  28%|██▊       | 142/500 [2:54:09<7:59:20, 80.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  29%|██▊       | 143/500 [2:55:15<7:32:34, 76.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  29%|██▉       | 144/500 [2:56:26<7:21:19, 74.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  29%|██▉       | 145/500 [2:57:33<7:06:26, 72.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  29%|██▉       | 146/500 [2:58:43<7:02:44, 71.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  29%|██▉       | 147/500 [2:59:54<6:59:05, 71.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  30%|██▉       | 148/500 [3:01:02<6:52:36, 70.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  30%|██▉       | 149/500 [3:02:11<6:48:58, 69.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  30%|███       | 150/500 [3:03:21<6:49:07, 70.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  30%|███       | 151/500 [3:04:29<6:43:19, 69.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  30%|███       | 152/500 [3:05:39<6:42:55, 69.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  31%|███       | 153/500 [3:06:51<6:47:40, 70.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  31%|███       | 154/500 [3:08:02<6:45:59, 70.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  31%|███       | 155/500 [3:09:08<6:37:51, 69.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  31%|███       | 156/500 [3:10:16<6:33:53, 68.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  31%|███▏      | 157/500 [3:11:25<6:33:58, 68.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  32%|███▏      | 158/500 [3:12:33<6:31:58, 68.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  32%|███▏      | 159/500 [3:13:42<6:31:13, 68.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  32%|███▏      | 160/500 [3:14:50<6:28:17, 68.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  32%|███▏      | 161/500 [3:15:58<6:26:22, 68.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  32%|███▏      | 162/500 [3:18:52<9:24:01, 100.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Baixar en bicicleta per Powell és *una puta idea estúpida*.\n",
      "Reason: La frase \"Bajar en bicicleta por Powell es una puta idea estúpida\" prové d’un capítol de la sèrie televisiva The Simpsons anomenat 'Treehouse of Horror XIV', emesa l’any 2003. Es tracta d’una traducció literal de l’expressió anglesa \"riding bikes down Powell is a fucking stupid idea\", que fa referència a un passatge fictici dins Springfield en què els nens fan servir bicicletes per baixar pel carrer Powell. El context de\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  33%|███▎      | 163/500 [3:20:04<8:33:51, 91.49s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  33%|███▎      | 164/500 [3:21:12<7:53:23, 84.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  33%|███▎      | 165/500 [3:22:21<7:25:45, 79.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  33%|███▎      | 166/500 [3:23:27<7:01:26, 75.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  33%|███▎      | 167/500 [3:24:37<6:50:02, 73.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  34%|███▎      | 168/500 [3:25:49<6:45:26, 73.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  34%|███▍      | 169/500 [3:26:57<6:36:27, 71.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  34%|███▍      | 170/500 [3:28:07<6:32:07, 71.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  34%|███▍      | 171/500 [3:29:14<6:22:56, 69.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  34%|███▍      | 172/500 [3:30:24<6:22:52, 70.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  35%|███▍      | 173/500 [3:31:31<6:16:47, 69.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  35%|███▍      | 174/500 [3:34:00<8:25:31, 93.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: No es diu la ciència immortal sense raó ey\n",
      "Reason: La traducció pot contenir errors gramaticals o sintàctics que afecten la comprensió del missatge original. En aquest cas, sembla haver-hi un error ortogràfic o gramatical que afecta la coherència de la frase traduïda.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  35%|███▌      | 175/500 [3:36:27<9:52:36, 109.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: jo com la merda\n",
      "Reason: La traducció pot contenir errors gramaticals o de vocabulari que afecten la comprensió del missatge original. En aquest cas, sembla que hi ha un problema de traducció que fa que el resultat final sigui difícil d'entendre o incorrecte gramaticalment.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  35%|███▌      | 176/500 [3:37:35<8:43:30, 96.95s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  35%|███▌      | 177/500 [3:38:41<7:51:53, 87.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  36%|███▌      | 178/500 [3:39:52<7:23:31, 82.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  36%|███▌      | 179/500 [3:41:00<6:57:29, 78.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  36%|███▌      | 180/500 [3:43:48<9:21:36, 105.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Desacreditat com en demostrat malament. Una vegada més, és un ximple ben conegut. Feu-vos un favor i mai prendre res del que diu remotament seriosament.\n",
      "Reason: La traducció pot tenir errors gramaticals o sintàctics. També hi ha paraules mal traduïdes o faltes d’ortografia. Per exemple: \"un\" hauria de ser \"una\", ja que la paraula anterior era femenina; també faltava l’accent agut sobre la \"e\". En general, la traducció sembla massa literal i manca fluïdesa.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  36%|███▌      | 181/500 [3:44:57<8:21:33, 94.34s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  36%|███▋      | 182/500 [3:46:06<7:39:42, 86.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  37%|███▋      | 183/500 [3:47:14<7:08:49, 81.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  37%|███▋      | 184/500 [3:48:23<6:46:50, 77.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  37%|███▋      | 185/500 [3:49:33<6:34:18, 75.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  37%|███▋      | 186/500 [3:50:43<6:25:43, 73.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  37%|███▋      | 187/500 [3:51:50<6:14:14, 71.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  38%|███▊      | 188/500 [3:52:58<6:07:26, 70.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  38%|███▊      | 189/500 [3:54:06<6:00:55, 69.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  38%|███▊      | 190/500 [3:55:12<5:55:17, 68.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  38%|███▊      | 191/500 [3:56:24<5:58:12, 69.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  38%|███▊      | 192/500 [3:57:34<5:58:39, 69.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  39%|███▊      | 193/500 [3:58:41<5:53:03, 69.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  39%|███▉      | 194/500 [3:59:50<5:52:08, 69.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  39%|███▉      | 195/500 [4:01:01<5:53:08, 69.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  39%|███▉      | 196/500 [4:03:52<8:26:05, 99.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: aw vostè no ha d'afaitar! l'afaitat en realitat causa encarnades com aquest tipus: 0\n",
      "Reason: La traducció pot tenir errors gramaticals o sintàctics que afecten la comprensió del missatge original. En concret, hi ha faltes d'ortografia i possibles incorreccions en la construcció de les frases. Per exemple, \"l'afaitat\" hauria de ser \"raspallar\", ja que es refereix a un procés diferent. Aquestes errades poden dificultar la lectura i interpretació correcta del text traduït.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  39%|███▉      | 197/500 [4:04:59<7:35:02, 90.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  40%|███▉      | 198/500 [4:06:05<6:57:38, 82.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  40%|███▉      | 199/500 [4:07:14<6:34:42, 78.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  40%|████      | 200/500 [4:08:21<6:15:50, 75.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  40%|████      | 201/500 [4:09:30<6:05:42, 73.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  40%|████      | 202/500 [4:10:37<5:54:08, 71.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  41%|████      | 203/500 [4:11:44<5:47:39, 70.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  41%|████      | 204/500 [4:12:53<5:44:30, 69.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  41%|████      | 205/500 [4:14:07<5:49:25, 71.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  41%|████      | 206/500 [4:15:14<5:41:07, 69.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  41%|████▏     | 207/500 [4:16:22<5:37:42, 69.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  42%|████▏     | 208/500 [4:17:28<5:32:22, 68.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  42%|████▏     | 209/500 [4:20:01<7:34:38, 93.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Mala sort, cabrons.\n",
      "Reason: Possible raó: El text original estava escrit en castellà i es va traduir directament al català sense fer servir un traductor automatitzat adequat o revisar la traducció manualment. Això pot haver provocat errors gramaticals i faltes d’ortografia que van afectar negativament la qualitat de la traducció.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  42%|████▏     | 210/500 [4:21:09<6:56:00, 86.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  42%|████▏     | 211/500 [4:22:17<6:27:49, 80.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  42%|████▏     | 212/500 [4:24:40<7:56:32, 99.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Aquest joc és en realitat pitjor del que esperava i sabia que seria dolent\n",
      "Reason: Possible raó: la traducció pot contenir errors o expressions inadequades que afecten negativament la claredat o precisió del missatge original.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  43%|████▎     | 213/500 [4:25:46<7:08:01, 89.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  43%|████▎     | 214/500 [4:26:54<6:34:45, 82.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  43%|████▎     | 215/500 [4:28:04<6:15:12, 78.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  43%|████▎     | 216/500 [4:29:14<6:00:54, 76.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  43%|████▎     | 217/500 [4:30:21<5:47:19, 73.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  44%|████▎     | 218/500 [4:31:29<5:37:52, 71.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  44%|████▍     | 219/500 [4:32:37<5:31:50, 70.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  44%|████▍     | 220/500 [4:33:48<5:29:56, 70.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  44%|████▍     | 221/500 [4:35:00<5:30:15, 71.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  44%|████▍     | 222/500 [4:36:09<5:26:54, 70.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  45%|████▍     | 223/500 [4:37:19<5:25:10, 70.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  45%|████▍     | 224/500 [4:38:29<5:23:34, 70.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  45%|████▌     | 225/500 [4:39:38<5:20:23, 69.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  45%|████▌     | 226/500 [4:40:47<5:18:00, 69.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  45%|████▌     | 227/500 [4:43:42<7:40:56, 101.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: No tens cor si anomenes “druggies” a la gent que fuma marihuana i he acabat de discutir amb tu, que tinguis un bon dia.\n",
      "Reason: La frase \"No tens cor\" es refereix a algú que manca d’empatia o compassió cap als altres. En aquest context, l’autor està expressant ira perquè se sent menyspreat pel fet que l’interlocutor els hagi anomenat \"drogat\". Per tant, la intenció de les paraules és insultar l’altra persona. Això fa que sigui difícil traduir aquesta part sense perdre matisos importants.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  46%|████▌     | 228/500 [4:44:52<6:55:47, 91.72s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  46%|████▌     | 229/500 [4:47:53<8:55:00, 118.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Argh. L'abús més estúpid i innecessari dels mestres de poder ho fan. Alguns particularment estúpids almenys.\n",
      "Reason: La traducció sembla haver estat automatitzada mitjançant un traductor com ara Google Translate. El resultat conté errors gramaticals i lèxics que afecten la comprensió. Per exemple, \"Argh\" es pot traduir com \"Ai!\". Però aquí significa \"Uau!\", cosa que confondria els parlants catalans. També hi ha faltes d’ortografia, com ara \"ho\", quan hauria de ser \"això\". I també falta algun article o preposició, com ara \"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  46%|████▌     | 230/500 [4:49:00<7:44:17, 103.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  46%|████▌     | 231/500 [4:50:11<6:59:51, 93.65s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  46%|████▋     | 232/500 [4:53:00<8:38:23, 116.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: ARGH!!\n",
      "Reason: La traducció automàtica d’aquesta paraula anglesa \"ARGH\" pot donar lloc a diverses paraules catalanes com ara \"AAAARG\", \"AAAAAAAGH\", etc., que poden resultar confuses o fins i tot sense sentit en la llengua catalana. Per tant, cal seleccionar acuradament l'opció més adequada segons el context. En aquest cas concret, sembla que es tracta d'una expressió d'enuig, així doncs, la millor opció seria probablement \"AAAARG\". No obstant això\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  47%|████▋     | 233/500 [4:54:07<7:31:48, 101.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  47%|████▋     | 234/500 [4:55:19<6:50:38, 92.63s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  47%|████▋     | 235/500 [4:56:28<6:17:49, 85.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  47%|████▋     | 236/500 [4:57:37<5:54:03, 80.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  47%|████▋     | 237/500 [4:58:44<5:34:55, 76.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  48%|████▊     | 238/500 [5:01:02<6:54:12, 94.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Tenint aquest problema, així que realment em fa en\n",
      "Reason: La traducció pot tenir errors gramaticals o sintàctics, la qual cosa afecta negativament la comprensió del missatge original.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  48%|████▊     | 239/500 [5:02:12<6:20:06, 87.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  48%|████▊     | 240/500 [5:03:18<5:51:15, 81.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  48%|████▊     | 241/500 [5:04:28<5:36:05, 77.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  48%|████▊     | 242/500 [5:05:37<5:22:20, 74.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  49%|████▊     | 243/500 [5:06:47<5:14:57, 73.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  49%|████▉     | 244/500 [5:07:53<5:03:55, 71.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  49%|████▉     | 245/500 [5:09:02<5:00:18, 70.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  49%|████▉     | 246/500 [5:10:08<4:53:45, 69.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  49%|████▉     | 247/500 [5:11:18<4:52:48, 69.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  50%|████▉     | 248/500 [5:14:00<6:47:41, 97.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: No hi ha res adorable en aquest home aterridor\n",
      "Reason: La traducció pot contenir errors gramaticals o sintàctics que afecten la comprensió del missatge original. En concret, l'ús de \"No\" com a adverbi davant d'un adjectiu pot canviar el significat de manera inesperada. També es podrien haver produït altres errors de traducció relacionats amb les diferències entre els sistemes lingüístics espanyol/català i anglès.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  50%|████▉     | 249/500 [5:15:12<6:15:23, 89.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  50%|█████     | 250/500 [5:16:20<5:46:40, 83.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  50%|█████     | 251/500 [5:17:31<5:29:54, 79.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  50%|█████     | 252/500 [5:19:56<6:49:16, 99.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Nois aquest equip és  ⁇ \n",
      "Reason: Possible problema de traducció des d’una altra llengua estrangera que no sigui l’anglès. El signe «⁇» pot tenir diferents significats segons la llengua d’origen.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  51%|█████     | 253/500 [5:21:03<6:08:44, 89.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  51%|█████     | 254/500 [5:22:11<5:40:55, 83.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  51%|█████     | 255/500 [5:23:21<5:23:25, 79.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  51%|█████     | 256/500 [5:24:30<5:09:04, 76.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  51%|█████▏    | 257/500 [5:25:40<5:00:27, 74.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  52%|█████▏    | 258/500 [5:28:22<6:45:49, 100.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Això és increïblement descoratjador.\n",
      "Reason: La traducció pot ser considerada com de mala qualitat degut als errors gramaticals presents en la frase traduïda. Concretament, hi ha un error d'ortografia (\"d\" en lloc de \"de\") que afecta l'estructura gramatical de la frase. Aquest tipus d'errors poden fer difícil o impossible entendre el missatge original, cosa que fa baixar la qualitat de la traducció.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  52%|█████▏    | 259/500 [5:29:30<6:05:08, 90.90s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  52%|█████▏    | 260/500 [5:32:03<7:18:06, 109.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: El mateix. El borrissol corporal (en el meu propi cos...no m'importa el que faci ningú amb el seu borrissol corporal) em fa fàstic d'una puta vegada.\n",
      "Reason: La traducció sembla tenir errors gramaticals o sintàctics, la qual cosa afecta negativament la comprensió del text original. Aquest fet pot fer baixar la qualitat de la traducció.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  52%|█████▏    | 261/500 [5:33:13<6:29:18, 97.73s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  52%|█████▏    | 262/500 [5:34:23<5:53:36, 89.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  53%|█████▎    | 263/500 [5:35:29<5:25:07, 82.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  53%|█████▎    | 264/500 [5:36:39<5:08:57, 78.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  53%|█████▎    | 265/500 [5:37:50<4:59:30, 76.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  53%|█████▎    | 266/500 [5:40:54<7:03:47, 108.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Rebutja la teva humanitat voluntàriament i posa l'odi pur, la manca de moral, la sociopatia i l'altitud sàdica dins de la teva ànima sense poder fer marxa enrere.\n",
      "Reason: La traducció pot tenir errors gramaticals o sintàctics que afecten negativament la comprensió del missatge original. També hi ha paraules mal traduïdes que poden canviar el significat de les frases. Per exemple, \"voluntàriament\" hauria d'haver estat traduït com \"voluntària\", ja que es refereix a un acte realitzat lliurement i conscientment. D'altra banda, \"sociopatia\" està correctament traduïda però apareix dues vegades seguides en el mateix paràgraf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  53%|█████▎    | 267/500 [5:42:04<6:16:32, 96.96s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  54%|█████▎    | 268/500 [5:43:10<5:38:47, 87.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  54%|█████▍    | 269/500 [5:44:16<5:12:28, 81.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  54%|█████▍    | 270/500 [5:45:25<4:57:08, 77.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  54%|█████▍    | 271/500 [5:47:52<6:15:48, 98.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: [NOM] Els tatuatges van ser dissenyats específicament per augmentar el seu físic. Aquest noi sembla que la seva germana petita li va fer un gargot mentre dormia.\n",
      "Reason: La traducció pot tenir errors gramaticals o sintàctics, cosa que afecta negativament la comprensió del missatge original.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  54%|█████▍    | 272/500 [5:48:59<5:38:20, 89.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  55%|█████▍    | 273/500 [5:50:07<5:13:16, 82.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  55%|█████▍    | 274/500 [5:51:17<4:57:27, 78.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  55%|█████▌    | 275/500 [5:52:28<4:47:10, 76.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  55%|█████▌    | 276/500 [5:53:35<4:35:07, 73.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  55%|█████▌    | 277/500 [5:54:42<4:26:09, 71.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  56%|█████▌    | 278/500 [5:55:54<4:25:15, 71.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  56%|█████▌    | 279/500 [5:57:02<4:20:05, 70.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  56%|█████▌    | 280/500 [5:58:10<4:15:59, 69.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  56%|█████▌    | 281/500 [5:59:21<4:16:13, 70.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  56%|█████▋    | 282/500 [6:00:30<4:13:24, 69.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  57%|█████▋    | 283/500 [6:01:41<4:13:22, 70.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  57%|█████▋    | 284/500 [6:02:52<4:13:46, 70.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  57%|█████▋    | 285/500 [6:04:01<4:10:35, 69.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  57%|█████▋    | 286/500 [6:06:39<5:44:16, 96.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Després de veure TLJ, em resulta impossible veure TFA. És una seqüela d'alguna pel·lícula, però aquesta pel·lícula no és TFA.\n",
      "Reason: La traducció sembla estar feta amb un traductor automàtic que ha generat frases poc naturals o ambigües com ara \"és una seqüela d'una pel·lícula\", la qual cosa fa difícil entendre si es refereix a una pel·lícula o a alguna altra cosa.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  57%|█████▋    | 287/500 [6:07:48<5:13:34, 88.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  58%|█████▊    | 288/500 [6:08:57<4:51:06, 82.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  58%|█████▊    | 289/500 [6:10:06<4:35:54, 78.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  58%|█████▊    | 290/500 [6:11:14<4:23:33, 75.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  58%|█████▊    | 291/500 [6:12:22<4:14:15, 72.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  58%|█████▊    | 292/500 [6:13:31<4:08:41, 71.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  59%|█████▊    | 293/500 [6:14:40<4:05:25, 71.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  59%|█████▉    | 294/500 [6:15:49<4:02:02, 70.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  59%|█████▉    | 295/500 [6:17:02<4:02:57, 71.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  59%|█████▉    | 296/500 [6:18:10<3:58:47, 70.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  59%|█████▉    | 297/500 [6:19:16<3:53:21, 68.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  60%|█████▉    | 298/500 [6:20:26<3:53:05, 69.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  60%|█████▉    | 299/500 [6:21:35<3:51:44, 69.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  60%|██████    | 300/500 [6:22:45<3:51:42, 69.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  60%|██████    | 301/500 [6:23:55<3:51:02, 69.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  60%|██████    | 302/500 [6:25:06<3:50:32, 69.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  61%|██████    | 303/500 [6:26:13<3:46:25, 68.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  61%|██████    | 304/500 [6:28:45<5:07:27, 94.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Només dóna-li el seu maleït control total del govern i els mitjans de comunicació, dóna-li els seus maleïts camps de concentració, dóna-li la seva maleïda Solució Final.\n",
      "Reason: La traducció té un vocabulari ofensiu que pot ferir algunes persones. No obstant això, es tracta d'un problema lingüístic més que de qualitat de traducció.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  61%|██████    | 305/500 [6:29:54<4:40:51, 86.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  61%|██████    | 306/500 [6:31:05<4:24:44, 81.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  61%|██████▏   | 307/500 [6:32:15<4:11:21, 78.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  62%|██████▏   | 308/500 [6:33:22<3:59:45, 74.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  62%|██████▏   | 309/500 [6:34:28<3:50:14, 72.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  62%|██████▏   | 310/500 [6:37:23<5:26:18, 103.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Dóna-li 3 dies, quan tots els punts de venda de MSM es retractin tranquil·lament de la història.\n",
      "Reason: Possible problemes de traducció: \"MSM\" pot referir-se a un acrònim o terme que potser no està clar sense context addicional. El nombre \"3\" també pot ser confús si no queda clar quin tipus d’intervals numèrics estan inclosos aquí. Finalment, l’expressió \"retractar-se tranquil·lament\" pot necessitar més precisió cultural o idiomàtica perquè sigui clara per als parlants catalans.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  62%|██████▏   | 311/500 [6:38:29<4:49:45, 91.99s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  62%|██████▏   | 312/500 [6:39:37<4:25:47, 84.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  63%|██████▎   | 313/500 [6:40:46<4:09:32, 80.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  63%|██████▎   | 314/500 [6:43:16<5:12:42, 100.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: No. Tristament, a principis dels 30\n",
      "Reason: La traducció conté paraules que no són correctes gramaticalment o bé estan mal utilitzades. Per exemple \"Tristament\" hauria d'estar escrit com \"Malauradament\". Això pot afectar la comprensió del missatge original.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  63%|██████▎   | 315/500 [6:44:27<4:43:33, 91.96s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  63%|██████▎   | 316/500 [6:45:38<4:23:13, 85.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  63%|██████▎   | 317/500 [6:48:16<5:27:43, 107.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Totes les persones que van pujar a l'estació del pont de conserves aquest matí i van continuar empenyent-se i empenyent-se com a animals.\n",
      "Reason: La traducció pot tenir errors gramaticals o sintàctics, la qual cosa afecta negativament la comprensió del text original. També hi ha faltes d’ortografia i paraules mal traduïdes, fet que redueix encara més la qualitat de la traducció.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  64%|██████▎   | 318/500 [6:49:24<4:49:42, 95.51s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  64%|██████▍   | 319/500 [6:50:32<4:23:00, 87.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  64%|██████▍   | 320/500 [6:53:19<5:33:53, 111.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: HYS és la pitjor secció de comentaris d'Internet. Fa que els comentaris de Youtube s'assemblin al torn de preguntes dels jardiners.\n",
      "Reason: La traducció pot ser considerada com de mala qualitat perquè conté errors gramaticals i de vocabulari. Per exemple, \"HYS\" hauria de traduir-se com \"HYF\", i \"torn de preguntes dels jardiners\" seria més adequat com \"debat entre jardiners\". Aquests canvis milloren significativament la coherència i precisió del missatge original en anglès.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  64%|██████▍   | 321/500 [6:56:13<6:27:59, 130.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: prou robins  ⁇  biblioteques no sabria el que és l'estalvi, fins i tot si els va colpejar a la cara!  ⁇   ⁇   ⁇ \n",
      "Reason: La traducció està mal construïda gramaticalment. S’han traduït paraules individuals sense tenir present les estructures gramaticals pròpies del català. Per exemple, \"prou\" hauria d’anar seguit pel nom o un adjectiu, com ara \"robins\". En general, cal evitar traduccions literals quan es tracta de frases complexes perquè poden provocar errors gramaticals.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  64%|██████▍   | 322/500 [6:57:19<5:28:59, 110.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  65%|██████▍   | 323/500 [6:58:26<4:48:25, 97.77s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  65%|██████▍   | 324/500 [6:59:40<4:25:35, 90.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  65%|██████▌   | 325/500 [7:00:58<4:12:57, 86.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  65%|██████▌   | 326/500 [7:03:58<5:32:59, 114.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: els liberals són animals fastigosos\n",
      "Reason: La traducció pot ser de mala qualitat perquè conté un llenguatge ofensiu que fa referència als liberals com \"animals fastigosos\". Aquest tipus d’expressió pot resultar ofensiva o denigrant per a algunes persones i cultures, especialment quan es refereix a un grup polític o ideològic específic. És important tenir cura en fer traduccions per evitar expressions ofensives i garantir la sensibilitat cap a diferents grups culturals i lingüístics. En aquest cas concret, seria més adequat utilitzar un terme menys ofensiu o fins\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  65%|██████▌   | 327/500 [7:05:08<4:52:29, 101.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  66%|██████▌   | 328/500 [7:07:45<5:37:50, 117.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Això definitivament fa mal\n",
      "Reason: La traducció pot contenir errors gramaticals o sintàctics que afecten la comprensió del missatge original. En aquest cas, \"definitivament\" es tradueix com \"totalment\", però això crea una frase incoherent gramaticalment parlant. Per tant, la traducció hauria de dir alguna cosa així com \"Això sens dubte fa mal\".\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  66%|██████▌   | 329/500 [7:08:55<4:55:28, 103.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  66%|██████▌   | 330/500 [7:10:02<4:22:38, 92.70s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  66%|██████▌   | 331/500 [7:12:34<5:10:37, 110.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Tots els cabrons de tot arreu. Apesta que sigui tan fàcil d'utilitzar per a moltes altres coses.\n",
      "Reason: La traducció té errors gramaticals com ara l'ús incorrecte dels pronoms personals o la manca de concordança entre gèneres. Aquests errors podrien fer que la traducció fos difícil de comprendre pels parlants nadius catalans.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  66%|██████▋   | 332/500 [7:13:42<4:33:27, 97.66s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  67%|██████▋   | 333/500 [7:14:50<4:07:12, 88.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  67%|██████▋   | 334/500 [7:16:00<3:50:20, 83.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  67%|██████▋   | 335/500 [7:18:35<4:48:08, 104.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Odio, fotre, [NOM]\n",
      "Reason: Possible raó de la mala qualitat: El text conté paraules grolleres que podrien ferir els sentiments d’algú o resultar ofensives. Aquestes expressions són inadequades per a un llenguatge escrit formal i pot ser preferible evitar-les si es vol mantenir un nivell adequat de professionalitat.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  67%|██████▋   | 336/500 [7:19:46<4:18:51, 94.71s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  67%|██████▋   | 337/500 [7:20:53<3:54:22, 86.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  68%|██████▊   | 338/500 [7:23:16<4:38:28, 103.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Va publicar sobre racistes blancs en una publicació que no té res a veure amb el racisme. Bastant segur que és simplement racista.\n",
      "Reason: La traducció pot tenir errors gramaticals o sintàctics, la qual cosa afecta negativament la comprensió del missatge original.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  68%|██████▊   | 339/500 [7:24:22<4:07:30, 92.24s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  68%|██████▊   | 340/500 [7:26:53<4:52:49, 109.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: \"Els seus intents de ser \"\"atrevida\"\" cauen en sac trencat són increïblement cringeworthy.\"\n",
      "Reason: La traducció pot tenir errors gramaticals o sintàctics que afecten la comprensió del missatge original. En aquest cas concret, hi ha un error gramatical en l'ús dels signes d'interrogació i exclamació.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  68%|██████▊   | 341/500 [7:28:02<4:18:44, 97.64s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  68%|██████▊   | 342/500 [7:30:32<4:58:15, 113.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Pobre home:(\n",
      "Reason: Possible problema de traducció: la frase \"Poor man:\" pot haver estat traduïda literalment des de l'anglès sense tenir en compte les regles gramaticals o expressions equivalents en català. Això resultaria en una traducció poc natural o incorrecta gramaticalment.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  69%|██████▊   | 343/500 [7:31:40<4:20:37, 99.60s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  69%|██████▉   | 344/500 [7:32:48<3:54:10, 90.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  69%|██████▉   | 345/500 [7:33:57<3:36:29, 83.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  69%|██████▉   | 346/500 [7:35:02<3:20:32, 78.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  69%|██████▉   | 347/500 [7:36:11<3:12:26, 75.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  70%|██████▉   | 348/500 [7:37:20<3:06:15, 73.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  70%|██████▉   | 349/500 [7:38:29<3:01:33, 72.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  70%|███████   | 350/500 [7:39:37<2:57:36, 71.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  70%|███████   | 351/500 [7:40:45<2:53:31, 69.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  70%|███████   | 352/500 [7:41:53<2:51:04, 69.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  71%|███████   | 353/500 [7:42:58<2:46:42, 68.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  71%|███████   | 354/500 [7:44:04<2:44:18, 67.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  71%|███████   | 355/500 [7:45:14<2:45:09, 68.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  71%|███████   | 356/500 [7:46:22<2:43:32, 68.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  71%|███████▏  | 357/500 [7:47:32<2:43:43, 68.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  72%|███████▏  | 358/500 [7:48:40<2:42:14, 68.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  72%|███████▏  | 359/500 [7:49:49<2:41:21, 68.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  72%|███████▏  | 360/500 [7:50:59<2:41:10, 69.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  72%|███████▏  | 361/500 [7:52:07<2:39:32, 68.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  72%|███████▏  | 362/500 [7:53:14<2:36:27, 68.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  73%|███████▎  | 363/500 [7:54:22<2:35:25, 68.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  73%|███████▎  | 364/500 [7:55:31<2:34:48, 68.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  73%|███████▎  | 365/500 [7:56:38<2:33:15, 68.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  73%|███████▎  | 366/500 [7:57:46<2:31:51, 67.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  73%|███████▎  | 367/500 [7:58:53<2:30:24, 67.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  74%|███████▎  | 368/500 [8:00:01<2:28:59, 67.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  74%|███████▍  | 369/500 [8:01:07<2:26:33, 67.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  74%|███████▍  | 370/500 [8:02:15<2:26:27, 67.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  74%|███████▍  | 371/500 [8:03:25<2:26:28, 68.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  74%|███████▍  | 372/500 [8:04:35<2:27:03, 68.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  75%|███████▍  | 373/500 [8:05:44<2:25:24, 68.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  75%|███████▍  | 374/500 [8:06:53<2:24:49, 68.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  75%|███████▌  | 375/500 [8:08:04<2:25:04, 69.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  75%|███████▌  | 376/500 [8:09:14<2:23:39, 69.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  75%|███████▌  | 377/500 [8:10:19<2:19:41, 68.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  76%|███████▌  | 378/500 [8:11:24<2:16:49, 67.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  76%|███████▌  | 379/500 [8:12:31<2:15:30, 67.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  76%|███████▌  | 380/500 [8:13:39<2:14:43, 67.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  76%|███████▌  | 381/500 [8:14:45<2:13:09, 67.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  76%|███████▋  | 382/500 [8:15:51<2:11:11, 66.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  77%|███████▋  | 383/500 [8:17:02<2:12:20, 67.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  77%|███████▋  | 384/500 [8:18:09<2:10:52, 67.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  77%|███████▋  | 385/500 [8:19:17<2:09:50, 67.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  77%|███████▋  | 386/500 [8:20:23<2:07:41, 67.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  77%|███████▋  | 387/500 [8:21:30<2:06:35, 67.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  78%|███████▊  | 388/500 [8:22:36<2:04:49, 66.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  78%|███████▊  | 389/500 [8:23:45<2:04:52, 67.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  78%|███████▊  | 390/500 [8:24:55<2:05:03, 68.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  78%|███████▊  | 391/500 [8:26:03<2:03:45, 68.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  78%|███████▊  | 392/500 [8:27:12<2:03:32, 68.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  79%|███████▊  | 393/500 [8:28:20<2:01:49, 68.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  79%|███████▉  | 394/500 [8:29:32<2:02:44, 69.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  79%|███████▉  | 395/500 [8:30:45<2:03:18, 70.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  79%|███████▉  | 396/500 [8:33:24<2:48:16, 97.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: LONDRES Sincerament ni tan sols entenc això\n",
      "Reason: La traducció pot tenir errors gramaticals o sintàctics que afecten la comprensió del missatge original. També hi ha faltes d'ortografia i possibles ambigüitats en la interpretació de les paraules utilitzades. En general, la traducció sembla estar feta sense gaire atenció als detalls, cosa que afecta negativament la claredat i precisió del missatge.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  79%|███████▉  | 397/500 [8:34:31<2:31:01, 87.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  80%|███████▉  | 398/500 [8:35:37<2:18:17, 81.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  80%|███████▉  | 399/500 [8:36:43<2:09:31, 76.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  80%|████████  | 400/500 [8:37:51<2:03:25, 74.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  80%|████████  | 401/500 [8:38:59<1:59:19, 72.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  80%|████████  | 402/500 [8:40:08<1:56:16, 71.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  81%|████████  | 403/500 [8:41:13<1:52:29, 69.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  81%|████████  | 404/500 [8:42:21<1:50:29, 69.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  81%|████████  | 405/500 [8:43:29<1:48:56, 68.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  81%|████████  | 406/500 [8:44:41<1:49:05, 69.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  81%|████████▏ | 407/500 [8:45:52<1:48:22, 69.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  82%|████████▏ | 408/500 [8:47:03<1:47:55, 70.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  82%|████████▏ | 409/500 [8:48:10<1:45:16, 69.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  82%|████████▏ | 410/500 [8:49:20<1:44:29, 69.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  82%|████████▏ | 411/500 [8:50:32<1:44:08, 70.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  82%|████████▏ | 412/500 [8:51:39<1:41:22, 69.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  83%|████████▎ | 413/500 [8:52:48<1:40:26, 69.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  83%|████████▎ | 414/500 [8:53:56<1:38:35, 68.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  83%|████████▎ | 415/500 [8:55:05<1:37:28, 68.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  83%|████████▎ | 416/500 [8:56:12<1:35:38, 68.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  83%|████████▎ | 417/500 [8:57:23<1:35:41, 69.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  84%|████████▎ | 418/500 [8:58:30<1:33:44, 68.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  84%|████████▍ | 419/500 [8:59:38<1:32:10, 68.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  84%|████████▍ | 420/500 [9:00:45<1:30:41, 68.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  84%|████████▍ | 421/500 [9:01:55<1:30:03, 68.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  84%|████████▍ | 422/500 [9:03:03<1:28:50, 68.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  85%|████████▍ | 423/500 [9:05:23<1:55:33, 90.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Deixar de dir això? Fa que la meva panxa es molesti  ⁇ \n",
      "Reason: La traducció pot tenir errors gramaticals o sintàctics, cosa que afecta negativament la comprensió del missatge original.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  85%|████████▍ | 424/500 [9:06:31<1:45:22, 83.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  85%|████████▌ | 425/500 [9:07:38<1:38:13, 78.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  85%|████████▌ | 426/500 [9:08:45<1:32:35, 75.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  85%|████████▌ | 427/500 [9:09:56<1:29:46, 73.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  86%|████████▌ | 428/500 [9:11:04<1:26:23, 71.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  86%|████████▌ | 429/500 [9:12:14<1:24:23, 71.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  86%|████████▌ | 430/500 [9:13:24<1:22:43, 70.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  86%|████████▌ | 431/500 [9:14:32<1:20:47, 70.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  86%|████████▋ | 432/500 [9:15:38<1:17:54, 68.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  87%|████████▋ | 433/500 [9:16:45<1:16:26, 68.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  87%|████████▋ | 434/500 [9:17:56<1:15:57, 69.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  87%|████████▋ | 435/500 [9:19:05<1:14:45, 69.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  87%|████████▋ | 436/500 [9:20:12<1:13:01, 68.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  87%|████████▋ | 437/500 [9:21:19<1:11:28, 68.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  88%|████████▊ | 438/500 [9:22:28<1:10:42, 68.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  88%|████████▊ | 439/500 [9:23:36<1:09:14, 68.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  88%|████████▊ | 440/500 [9:26:14<1:35:08, 95.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: FBI!! OBRIR!!!\n",
      "Reason: Puc dir que aquest text té un error ortogràfic (\"FBI\" hauria d’escriure's \"FBI!!\"), però no tinc prou informació sobre la llengua original ni el context per determinar si es tracta d'una mala traducció o no. Per tant, només puc donar una resposta general sense especificar els motius concrets de la baixa qualitat.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  88%|████████▊ | 441/500 [9:29:02<1:55:10, 117.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: El repte doble gos.\n",
      "Reason: La traducció pot tenir errors gramaticals o sintàctics que afecten la claredat del missatge original. En aquest cas, sembla haver-hi un error ortogràfic que afecta la comprensió del terme \"doble\" en relació al concepte de desafiament. Això es deu probablement a l’ús inadequat d’accents diacrítics en paraules compostes com ara \"doble\". Per tant, la traducció hauria estat més precisa si hagués utilitzat correctament els accents diacrítics\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  88%|████████▊ | 442/500 [9:31:31<2:02:21, 126.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Emo!!\n",
      "Reason: Possible raó de mala qualitat: la paraula \"Emo\" pot tenir diferents significats segons el context; aquí sembla que es refereix a un estil musical o subcultura, però sense més informació sobre el context, és difícil determinar si aquesta traducció és correcta.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  89%|████████▊ | 443/500 [9:32:40<1:43:55, 109.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  89%|████████▉ | 444/500 [9:33:50<1:31:08, 97.65s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  89%|████████▉ | 445/500 [9:34:58<1:21:17, 88.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  89%|████████▉ | 446/500 [9:36:09<1:14:55, 83.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  89%|████████▉ | 447/500 [9:37:17<1:09:25, 78.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  90%|████████▉ | 448/500 [9:38:25<1:05:34, 75.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  90%|████████▉ | 449/500 [9:39:32<1:01:59, 72.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  90%|█████████ | 450/500 [9:40:44<1:00:36, 72.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  90%|█████████ | 451/500 [9:41:52<58:09, 71.22s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  90%|█████████ | 452/500 [9:43:02<56:36, 70.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  91%|█████████ | 453/500 [9:45:50<1:18:29, 100.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Els seus controls de Twitter també són clarament un maleït idiota.\n",
      "Reason: La traducció pot tenir errors gramaticals o sintàctics que afecten la comprensió del missatge original. En aquest cas concret, hi ha faltes d’ortografia com ara \"maleït\" que podrien haver estat mal traduïdes des de l'anglès. També es poden observar algunes paraules manllevades sense adaptar adequadament les formes gramaticals catalanes corresponents. Per tant, aquesta traducció té una puntuació baixa segons els criteris esmentats anteriorment.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  91%|█████████ | 454/500 [9:46:57<1:09:08, 90.19s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  91%|█████████ | 455/500 [9:49:56<1:27:37, 116.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: sembla immadura, jugant a jocs mentals. Jo seria directe i si encara segueix jugant a deixar-la anar. sembla un cercador d'atenció.\n",
      "Reason: La traducció sembla tenir errors gramaticals o sintàctics que la fan difícil de comprendre, especialment perquè hi ha paraules que podrien traduir-se millor. Per exemple, \"immadur\" es pot substituir per \"juvenil\", ja que l'edat no té res a veure amb els aspectes psicològics descrits; també caldria revisar les expressions com ara \"deixar-la anar\". En general, cal millorar la precisió lingüística i evitar traduccions literals poc naturals.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  91%|█████████ | 456/500 [9:51:03<1:14:34, 101.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  91%|█████████▏| 457/500 [9:52:12<1:05:54, 91.98s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  92%|█████████▏| 458/500 [9:55:14<1:23:12, 118.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Tenint en compte el cul de cavall que heu fet de l'últim, crec que és millor deixar aquesta idea en un segon pla.\n",
      "Reason: La traducció pot ser considerada com de mala qualitat perquè conté errors gramaticals i sintàctics. Per exemple, \"cul\" hauria d'estar escrit sense accent, ja que es refereix a la part posterior del cos i no té cap altra funció gramatical rellevant en aquest context. També hi ha faltes d'ortografia com ara \"de\", que s'hauria d'escriure \"del\". Finalment, la frase \"crec que és millor deixar aquesta idea en un segon pla\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  92%|█████████▏| 459/500 [9:56:20<1:10:26, 103.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  92%|█████████▏| 460/500 [9:57:26<1:01:24, 92.11s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  92%|█████████▏| 461/500 [9:58:33<54:59, 84.60s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  92%|█████████▏| 462/500 [9:59:42<50:33, 79.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  93%|█████████▎| 463/500 [10:00:50<46:55, 76.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  93%|█████████▎| 464/500 [10:02:00<44:35, 74.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  93%|█████████▎| 465/500 [10:04:36<57:45, 99.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Mèxic o els EUA?\n",
      "Reason: La traducció pot tenir errors gramaticals o sintàctics que afecten la comprensió del missatge original. En aquest cas concret, es tracta d'una falta d'ortografia (\"Mèxic\" hauria de portar tilde), però també hi ha altres possibles errors. Per tant, la traducció té una puntuació global de 3/5.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  93%|█████████▎| 466/500 [10:05:44<50:46, 89.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  93%|█████████▎| 467/500 [10:08:30<1:01:57, 112.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: [NOM] és un imbècil. Per què treure la pilota al seu millor jugador i donar possiblement el millor RB en la nació l'oportunitat d'executar-lo.\n",
      "Reason: La traducció pot tenir errors gramaticals o sintàctics que afecten la comprensió del missatge original. També hi ha faltes d'ortografia i possibles ambigüitats en les expressions utilitzades. En general, la traducció sembla estar més pensada per a comunicar ràpidament i eficaçment el significat bàsic sense prestar molta atenció als detalls lingüístics.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  94%|█████████▎| 468/500 [10:09:37<52:40, 98.75s/it]   Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  94%|█████████▍| 469/500 [10:10:46<46:31, 90.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  94%|█████████▍| 470/500 [10:11:55<41:48, 83.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  94%|█████████▍| 471/500 [10:13:05<38:24, 79.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  94%|█████████▍| 472/500 [10:14:13<35:30, 76.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  95%|█████████▍| 473/500 [10:15:22<33:13, 73.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  95%|█████████▍| 474/500 [10:16:28<30:58, 71.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  95%|█████████▌| 475/500 [10:17:35<29:19, 70.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  95%|█████████▌| 476/500 [10:18:42<27:40, 69.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  95%|█████████▌| 477/500 [10:19:48<26:13, 68.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  96%|█████████▌| 478/500 [10:20:55<24:50, 67.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  96%|█████████▌| 479/500 [10:22:02<23:40, 67.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  96%|█████████▌| 480/500 [10:23:10<22:34, 67.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  96%|█████████▌| 481/500 [10:25:48<29:58, 94.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: No només això, els controls millorats no són res en absolut. No estic re-comprant Blood Money per a gràfics més bonics.\n",
      "Reason: La traducció pot tenir errors gramaticals o sintàctics que afecten la comprensió del missatge original. En aquest cas concret, es poden trobar faltes d’ortografia com \"re\" en lloc de \"per\", cosa que altera el significat de l’enunciat.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  96%|█████████▋| 482/500 [10:26:57<26:09, 87.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  97%|█████████▋| 483/500 [10:28:06<23:07, 81.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  97%|█████████▋| 484/500 [10:29:13<20:34, 77.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  97%|█████████▋| 485/500 [10:30:20<18:33, 74.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  97%|█████████▋| 486/500 [10:32:55<22:58, 98.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: també un dur NOOOO quan es disgusta\n",
      "Reason: Possible raó de la mala qualitat: El text conté paraules mal escrites o faltes d’ortografia que podrien dificultar la comprensió. En aquest cas, \"NOOO\" sembla estar mal escrit i pot causar confusió sobre si aquesta paraula forma part de l’expressió originalment escrita en anglès.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  97%|█████████▋| 487/500 [10:34:01<19:14, 88.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  98%|█████████▊| 488/500 [10:35:08<16:27, 82.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  98%|█████████▊| 489/500 [10:36:17<14:20, 78.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  98%|█████████▊| 490/500 [10:37:29<12:44, 76.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  98%|█████████▊| 491/500 [10:38:41<11:13, 74.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  98%|█████████▊| 492/500 [10:41:33<13:52, 104.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: És lletja, així que això podria afegir alguns mesos més.\n",
      "Reason: La frase \"És lletja\" probablement es refereix a alguna cosa física o visualment desagradable. Aquesta expressió pot tenir connotacions negatives i afectar la percepció d’una persona sobre un objecte o situació concret. En aquest cas, l'ús d'\"afegir uns quants mesos més\" sembla un intent de suavitzar les conseqüències negatives associades a la descripció inicial (\"lletja\"). No obstant això, aquesta expressió també té una certa quantitat de sarcasme\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations:  99%|█████████▊| 493/500 [10:42:39<10:49, 92.76s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  99%|█████████▉| 494/500 [10:43:50<08:37, 86.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  99%|█████████▉| 495/500 [10:44:58<06:43, 80.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  99%|█████████▉| 496/500 [10:46:04<05:05, 76.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations:  99%|█████████▉| 497/500 [10:47:12<03:41, 73.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations: 100%|█████████▉| 498/500 [10:49:51<03:18, 99.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discarded Translation:\n",
      "Text: Necessitàvem alguna manera de torturar un tipus per poder crear una religió.\n",
      "Reason: La traducció pot tenir errors gramaticals o sintàctics que afecten la comprensió del missatge original. També pot haver-hi faltes d'ortografia o paraules mal traduïdes que afectin l'exactitud de la traducció. En general, sembla que hi ha hagut poca atenció als detalls durant el procés de traducció.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating translations: 100%|█████████▉| 499/500 [10:51:00<01:30, 90.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Evaluating translations: 100%|██████████| 500/500 [10:52:08<00:00, 78.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 50 bad translations from dataset\n",
      "\n",
      "Saved 11,841 cleaned samples to 'goemotions.csv'\n",
      "\n",
      "Full pipeline finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "POSITIVE_SAMPLES_TO_ADD = 100\n",
    "TARGET_DISTRIBUTION = {\"positive\": 0.40, \"negative\": 0.30, \"neutral\": 0.30}\n",
    "SALAMANDRA_PATH = \"/home/user/Escritorio/TFM/salamandra-7b-instruct\"\n",
    "NUM_SAMPLES_TO_EVALUATE = 500\n",
    "\n",
    "for package in [\"datasets\", \"pandas\", \"tqdm\", \"ctranslate2\", \"sentencepiece\", \"huggingface_hub\", \"transformers\", \"torch\"]:\n",
    "    try:\n",
    "        __import__(package.split(\"[\")[0])\n",
    "    except ImportError:\n",
    "        print(f\"Installing required library: {package}\")\n",
    "        subprocess.check_call([\"pip\", \"install\", \"-q\", package])\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import ctranslate2\n",
    "import sentencepiece as spm\n",
    "from huggingface_hub import snapshot_download\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "emotion_id2label = [\"admiration\",\"amusement\",\"anger\",\"annoyance\",\"approval\",\"caring\",\"confusion\",\"curiosity\",\"desire\",\"disappointment\",\"disapproval\",\"disgust\",\"embarrassment\",\"excitement\",\"fear\",\"gratitude\",\"grief\",\"joy\",\"love\",\"nervousness\",\"optimism\",\"pride\",\"realization\",\"relief\",\"remorse\",\"sadness\",\"surprise\",\"neutral\"]\n",
    "sentiment_map = {\"positive\": {\"amusement\",\"excitement\",\"joy\",\"love\",\"desire\",\"optimism\",\"caring\",\"pride\",\"admiration\",\"gratitude\",\"relief\",\"approval\"},\"negative\": {\"fear\",\"nervousness\",\"remorse\",\"embarrassment\",\"disappointment\",\"sadness\",\"grief\",\"disgust\",\"anger\",\"annoyance\",\"disapproval\"},\"ambiguous\": {\"realization\",\"surprise\",\"curiosity\",\"confusion\"}}\n",
    "\n",
    "def parse_labels(labels_str):\n",
    "    if isinstance(labels_str, list): return labels_str\n",
    "    try: return [int(i) for i in str(labels_str).split(',')]\n",
    "    except (ValueError, TypeError): return []\n",
    "\n",
    "def classify_sentiment(emotion_ids):\n",
    "    counts = {\"positive\": 0, \"negative\": 0, \"ambiguous\": 0}\n",
    "    for eid in emotion_ids:\n",
    "        if isinstance(eid, int) and eid < len(emotion_id2label):\n",
    "            emotion = emotion_id2label[eid]\n",
    "            for category, emotions in sentiment_map.items():\n",
    "                if emotion in emotions: counts[category] += 1; break\n",
    "    if counts[\"positive\"] > counts[\"negative\"] and counts[\"positive\"] > counts[\"ambiguous\"]: return \"positive\"\n",
    "    elif counts[\"negative\"] > counts[\"positive\"] and counts[\"negative\"] > counts[\"ambiguous\"]: return \"negative\"\n",
    "    else: return \"neutral\"\n",
    "\n",
    "def add_sentiment_label(example):\n",
    "    parsed_ids = parse_labels(example[\"labels\"])\n",
    "    example[\"sentiment_label\"] = classify_sentiment(parsed_ids)\n",
    "    return example\n",
    "\n",
    "def initialize_models():\n",
    "    print(\"Initializing all models.\")\n",
    "    model_dir = snapshot_download(repo_id=\"projecte-aina/aina-translator-en-ca\", revision=\"main\")\n",
    "    sp_model_path = os.path.join(model_dir, \"spm.model\")\n",
    "    sp = spm.SentencePieceProcessor()\n",
    "    sp.load(sp_model_path)\n",
    "    translator = ctranslate2.Translator(model_dir, device=\"auto\")\n",
    "\n",
    "    print(\"  - AINA translator initialized.\")\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    eval_tokenizer = AutoTokenizer.from_pretrained(SALAMANDRA_PATH)\n",
    "    eval_model = AutoModelForCausalLM.from_pretrained(SALAMANDRA_PATH, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "    print(\"  - Salamandra evaluator LLM initialized.\")\n",
    "    return sp, translator, eval_tokenizer, eval_model\n",
    "\n",
    "def translate_en_to_ca(text, sp, translator):\n",
    "    try:\n",
    "        tokens = sp.encode(text, out_type=str)\n",
    "        translation = translator.translate_batch([tokens])\n",
    "        return sp.decode(translation[0][0][\"tokens\"])\n",
    "    except Exception: return \"\"\n",
    "\n",
    "def evaluate_translation(text_ca, tokenizer, model):\n",
    "    score_prompt = (\n",
    "        \"Ets un avaluador de qualitat de traducció en català. \"\n",
    "        \"Et donaré un text en català procedent de xarxes socials, \"\n",
    "        \"traduït automàticament des de l'anglès. \"\n",
    "        \"Avalua la qualitat de la traducció en una escala del 1 (molt dolenta) al 5 (excel·lent). \"\n",
    "        \"Ignora errors ortogràfics menors, abreviatures o estil informal. \"\n",
    "        \"Tingues en compte que el text pot ser informal o col·loquial ja que prové d'opinions de xarxes socials. \"\n",
    "        \"Respon només amb el número.\"\n",
    "        f\"\\n\\nText: {text_ca}\"\n",
    "    )\n",
    "    messages_score = [{\"role\": \"user\", \"content\": score_prompt}]\n",
    "    chat_text_score = tokenizer.apply_chat_template(messages_score, add_generation_prompt=True, tokenize=False)\n",
    "    inputs_score = tokenizer(chat_text_score, return_tensors=\"pt\").to(model.device)\n",
    "    outputs_score = model.generate(**inputs_score, max_new_tokens=5, temperature=0.1)\n",
    "    score_text = tokenizer.decode(outputs_score[0][len(inputs_score[\"input_ids\"][0]):], skip_special_tokens=True).strip()\n",
    "    try: score = int(score_text[0])\n",
    "    except (ValueError, IndexError): score = 3\n",
    "    explanation = \"\"\n",
    "    if score <= 2:\n",
    "        explanation_prompt = (\n",
    "            \"El text següent és una traducció automàtica del anglès al català. \"\n",
    "            \"La seva qualitat s'ha valorat amb una puntuació baixa (≤ 2) \"\n",
    "            \"en una escala de 1 a 5. Explica breument per què podria ser de baixa qualitat, \"\n",
    "            \"centrant-te en problemes de traducció i no en el contingut.\"\n",
    "            f\"\\n\\nText: {text_ca}\"\n",
    "        )\n",
    "        messages_explanation = [{\"role\": \"user\", \"content\": explanation_prompt}]\n",
    "        chat_text_expl = tokenizer.apply_chat_template(messages_explanation, add_generation_prompt=True, tokenize=False)\n",
    "        inputs_expl = tokenizer(chat_text_expl, return_tensors=\"pt\").to(model.device)\n",
    "        outputs_expl = model.generate(**inputs_expl, max_new_tokens=100, temperature=0.3)\n",
    "        explanation = tokenizer.decode(outputs_expl[0][len(inputs_expl[\"input_ids\"][0]):], skip_special_tokens=True).strip()\n",
    "    return score, explanation\n",
    "\n",
    "def classify_and_analyze_goemotions():\n",
    "    print(\"- Step 1: Analyzing GoEmotions Dataset\")\n",
    "    goemotions_train = load_dataset(\"go_emotions\", \"simplified\")[\"train\"]\n",
    "    classified_ds = goemotions_train.map(add_sentiment_label, batched=False)\n",
    "    return classified_ds\n",
    "\n",
    "def analyze_base_datasets():\n",
    "    print(\"\\n- Step 2: Analyzing Base Datasets (cassa.csv + guiacat.csv)\")\n",
    "    try:\n",
    "        combined_df = pd.concat([pd.read_csv(\"cassa.csv\"), pd.read_csv(\"guiacat.csv\")], ignore_index=True)\n",
    "        label_counts = combined_df['label'].value_counts().to_dict()\n",
    "        print(f\"Combined base dataset has {len(combined_df):,} rows. Distribution: {label_counts}\")\n",
    "        return label_counts\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}. Ensure 'cassa.csv' and 'guiacat.csv' are in the root path.\")\n",
    "        return None\n",
    "\n",
    "def collect_and_translate_goemotions(classified_ds, needed_counts, sp, translator):\n",
    "    print(\"\\n- Step 3: Collecting and Translating from GoEmotions\")\n",
    "    collected_samples = []\n",
    "    goemotions_iterator = iter(classified_ds)\n",
    "    with tqdm(total=sum(needed_counts.values()), desc=\"Collecting samples\") as pbar:\n",
    "        while sum(needed_counts.values()) > 0:\n",
    "            try: row = next(goemotions_iterator)\n",
    "            except StopIteration:\n",
    "                print(\"\\nWarning: Reached end of GoEmotions dataset before collecting all samples.\")\n",
    "                break\n",
    "            sentiment = row[\"sentiment_label\"]\n",
    "            if needed_counts.get(sentiment, 0) > 0:\n",
    "                translated_text = translate_en_to_ca(row[\"text\"], sp, translator)\n",
    "                if translated_text:\n",
    "                    collected_samples.append({\"text\": translated_text, \"label\": sentiment})\n",
    "                    needed_counts[sentiment] -= 1\n",
    "                    pbar.update(1)\n",
    "    return pd.DataFrame(collected_samples)\n",
    "\n",
    "def filter_bad_translations(df, num_samples, tokenizer, model):\n",
    "    print(f\"\\n- Step 4: Evaluating {num_samples} random translations before saving\")\n",
    "    if len(df) == 0: return df\n",
    "    sample_df = df.sample(n=min(num_samples, len(df)), random_state=42)\n",
    "    bad_texts = set()\n",
    "    for _, row in tqdm(sample_df.iterrows(), total=len(sample_df), desc=\"Evaluating translations\"):\n",
    "        score, explanation = evaluate_translation(row[\"text\"], tokenizer, model)\n",
    "        if score <= 2:\n",
    "            print(\"\\nDiscarded Translation:\")\n",
    "            print(f\"Text: {row['text']}\")\n",
    "            print(f\"Reason: {explanation}\\n\")\n",
    "            bad_texts.add(row[\"text\"])\n",
    "    if bad_texts:\n",
    "        print(f\"Removing {len(bad_texts)} bad translations from dataset\")\n",
    "        df = df[~df[\"text\"].isin(bad_texts)]\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    classified_goemotions = classify_and_analyze_goemotions()\n",
    "    base_counts = analyze_base_datasets()\n",
    "    if base_counts:\n",
    "        current_pos, current_neg, current_neu = base_counts.get(\"positive\",0), base_counts.get(\"negative\",0), base_counts.get(\"neutral\",0)\n",
    "        final_pos_count = current_pos + POSITIVE_SAMPLES_TO_ADD\n",
    "        total_final_size = final_pos_count / TARGET_DISTRIBUTION[\"positive\"]\n",
    "        needed_counts = {\n",
    "            \"positive\": POSITIVE_SAMPLES_TO_ADD,\n",
    "            \"negative\": max(0, int(total_final_size * TARGET_DISTRIBUTION[\"negative\"] - current_neg)),\n",
    "            \"neutral\": max(0, int(total_final_size * TARGET_DISTRIBUTION[\"neutral\"] - current_neu))\n",
    "        }\n",
    "        print(\"\\nCollection Plan:\")\n",
    "        for label, count in needed_counts.items(): print(f\"  Collect {label.capitalize()}: {count:,} rows\")\n",
    "        \n",
    "        sp_translator, ctranslate_translator, eval_tokenizer, eval_model = initialize_models()\n",
    "        \n",
    "        goemotions_df = collect_and_translate_goemotions(\n",
    "            classified_goemotions, \n",
    "            needed_counts.copy(), \n",
    "            sp_translator, \n",
    "            ctranslate_translator\n",
    "        )\n",
    "        \n",
    "        goemotions_df = filter_bad_translations(goemotions_df, NUM_SAMPLES_TO_EVALUATE, eval_tokenizer, eval_model)\n",
    "        \n",
    "        output_filename = \"goemotions.csv\"\n",
    "        goemotions_df.to_csv(output_filename, index=False)\n",
    "        print(f\"\\nSaved {len(goemotions_df):,} cleaned samples to '{output_filename}'\")\n",
    "        \n",
    "    print(\"\\nFull pipeline finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b390fba",
   "metadata": {},
   "source": [
    "## 4. Create the Final Dataset\n",
    "\n",
    "The final step consists of generating the training, validation, and test splits. After combining the previously processed datasets, the rows are shuffled to ensure randomness and reduce potential ordering biases. The data is then divided into three subsets: 80% for training, 10% for validation, and 10% for testing. Finally, the resulting splits are stored as separate CSV files named `train.csv`, `validation.csv`, and `test.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f191c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input files:\n",
      "  - Loaded 'cassa.csv' with 6,400 rows.\n",
      "  - Loaded 'goemotions.csv' with 11,638 rows.\n",
      "  - Loaded 'guiacat.csv' with 5,750 rows.\n",
      "\n",
      "Combined dataset has a total of 23,788 rows.\n",
      "Dataset shuffled successfully.\n",
      "\n",
      "Saving final CSV files\n",
      "\n",
      "Process Complete\n",
      "'train.csv' (19,030 rows):\n",
      "  Distribution: 40.5% Positive, 30.1% Negative, 29.4% Neutral\n",
      "'validation.csv' (2,379 rows):\n",
      "  Distribution: 38.1% Positive, 30.4% Negative, 31.4% Neutral\n",
      "'test.csv' (2,379 rows):\n",
      "  Distribution: 42.1% Positive, 28.2% Negative, 29.8% Neutral\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except ImportError:\n",
    "    subprocess.check_call([\"pip\", \"install\", \"-q\", \"scikit-learn\"])\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "INPUT_FILES = [\"cassa.csv\", \"goemotions.csv\", \"guiacat.csv\"]\n",
    "OUTPUT_FILES = {\n",
    "    \"train\": \"train.csv\",\n",
    "    \"validation\": \"validation.csv\",\n",
    "    \"test\": \"test.csv\"\n",
    "}\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def print_distribution(df, name):\n",
    "    total_rows = len(df)\n",
    "    label_dist = df['label'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    pos_pct = label_dist.get('positive', 0)\n",
    "    neg_pct = label_dist.get('negative', 0)\n",
    "    neu_pct = label_dist.get('neutral', 0)\n",
    "    \n",
    "    print(f\"'{name}' ({total_rows:,} rows):\")\n",
    "    print(f\"  Distribution: {pos_pct:.1f}% Positive, {neg_pct:.1f}% Negative, {neu_pct:.1f}% Neutral\")\n",
    "\n",
    "def combine_and_split_datasets():\n",
    "    dataframes = []\n",
    "    print(\"Reading input files:\")\n",
    "    for file in INPUT_FILES:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            dataframes.append(df)\n",
    "            print(f\"  - Loaded '{file}' with {len(df):,} rows.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"  - Warning: '{file}' not found. Skipping.\")\n",
    "    \n",
    "    if not dataframes:\n",
    "        print(\"\\nError: No data files found. Aborting.\")\n",
    "        return\n",
    "\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    print(f\"\\nCombined dataset has a total of {len(combined_df):,} rows.\")\n",
    "\n",
    "    shuffled_df = combined_df.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "    print(\"Dataset shuffled successfully.\")\n",
    "\n",
    "    train_df, temp_df = train_test_split(\n",
    "        shuffled_df, test_size=0.2, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    validation_df, test_df = train_test_split(\n",
    "        temp_df, test_size=0.5, random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    print(\"\\nSaving final CSV files\")\n",
    "    train_df.to_csv(OUTPUT_FILES[\"train\"], index=False)\n",
    "    validation_df.to_csv(OUTPUT_FILES[\"validation\"], index=False)\n",
    "    test_df.to_csv(OUTPUT_FILES[\"test\"], index=False)\n",
    "\n",
    "    print(\"\\nProcess Complete\")\n",
    "    print_distribution(train_df, \"train.csv\")\n",
    "    print_distribution(validation_df, \"validation.csv\")\n",
    "    print_distribution(test_df, \"test.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    combine_and_split_datasets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
