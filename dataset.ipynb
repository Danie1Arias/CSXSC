{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f444ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1fc6f3",
   "metadata": {},
   "source": [
    "# Classificador de Sentiments a Xarxes Socials en Catal√† (CSXSC): Dataset\n",
    "\n",
    "**Author:** Daniel Arias C√°mara  \n",
    "**Date:** 25-07-2025  \n",
    "\n",
    "**Description:**  This notebook aims to build a high-quality dataset for fine-tuning the **CSXSC** model. The dataset is constructed by combining trusted data sources, including structured sentiment corpora and translated social media content. Details on data origin and preprocessing steps are provided in the sections below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfd3695",
   "metadata": {},
   "source": [
    "## 1. GuiaCat Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902f794",
   "metadata": {},
   "source": [
    "**Description:** This dataset consists of 5,750 restaurant reviews in Catalan, sourced from the GuiaCat platform. Each review includes individual ratings for service, food, price-quality ratio, and atmosphere, along with an overall average score.\n",
    "\n",
    "**Access:** [projecte-aina/GuiaCat on Hugging Face](https://huggingface.co/datasets/projecte-aina/GuiaCat)\n",
    "\n",
    "**Source:** Aina Project\n",
    "\n",
    "**Notes:**  \n",
    "The dataset is divided into three subsets:  \n",
    "- **Train:** 1,750 rows  \n",
    "- **Validation:** 500 rows  \n",
    "- **Test:** 500 rows  \n",
    "\n",
    "The original fields are: Service, Food, Price-quality, Environment, Avg, Text, and Label.  \n",
    "For our purposes, we retain only the Text and Label fields, discarding the rest.\n",
    "\n",
    "The Label field includes five sentiment categories:  \n",
    "- Molt bo (Very good)  \n",
    "- Bo (Good)  \n",
    "- Regular (Average)  \n",
    "- Dolent (Bad)  \n",
    "- Molt dolent (Very bad)\n",
    "\n",
    "These are grouped into three classes for sentiment classification:  \n",
    "- **Positive:** Molt bo and Bo  \n",
    "- **Neutral:** Regular  \n",
    "- **Negative:** Dolent and Molt dolent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d57d28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/ai/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Creating CSV from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 286.28ba/s]\n",
      "Creating CSV from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 529.52ba/s]\n",
      "Creating CSV from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 532.14ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'text': 'El lloc √©s acollidor. El tracte, familiar. Els plats s√≥n casolans, abundants i de qualitat! Productes de la terra com embutits i altres de la zona. Hi tornarem segur!', 'label': 'positive'}\n",
      "Validation: {'text': 'Bon Menjar i bon tracte en un restaurant que seg√∫ hi tornar√†s un altre vegada.', 'label': 'positive'}\n",
      "Test: {'text': \"Fant√†stic restaurant ,una carta plena de plats creatius i cuina de temporada que sempre es d'agrair , i el que varem menjar nosaltres molt b√©, estic segura que tornar√© no ho dubtar√©.El tracte b√≥ i l'espai molt acollidor.\", 'label': 'positive'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    import datasets\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"-q\", \"datasets\"])\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds_guiacat = load_dataset(\"projecte-aina/GuiaCat\")\n",
    "ds = {}\n",
    "\n",
    "for split in ds_guiacat:\n",
    "    drop_columns = [col for col in ds_guiacat[split].column_names if col not in [\"text\", \"label\"]]\n",
    "    ds[split] = ds_guiacat[split].remove_columns(drop_columns)\n",
    "\n",
    "    def relabel(opinion):\n",
    "        label = opinion[\"label\"].lower()\n",
    "        if label in [\"molt bo\", \"bo\"]:\n",
    "            opinion[\"label\"] = \"positive\"\n",
    "        elif label == \"regular\":\n",
    "            opinion[\"label\"] = \"neutral\"\n",
    "        elif label in [\"dolent\", \"molt dolent\"]:\n",
    "            opinion[\"label\"] = \"negative\"\n",
    "        return opinion\n",
    "\n",
    "    ds[split] = ds[split].map(relabel)\n",
    "\n",
    "output_dirs = {\n",
    "    \"train\": \"train\",\n",
    "    \"validation\": \"validate\",\n",
    "    \"test\": \"test\"\n",
    "}\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    os.makedirs(split, exist_ok=True)\n",
    "    output_path = os.path.join(split, \"guiacat.csv\")\n",
    "    ds[split].to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Train:\", ds[\"train\"][0])\n",
    "print(\"Validation:\", ds[\"validation\"][0])\n",
    "print(\"Test:\", ds[\"test\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6754525",
   "metadata": {},
   "source": [
    "## 2. Catalan Structured Sentiment Analysis (CaSSA) Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1631b602",
   "metadata": {},
   "source": [
    "**Description:** The CaSSA dataset contains 6,400 reviews and forum messages in Catalan, annotated at the fine-grained level with polar expressions. Each text instance is labeled with all the sentiment expressions it contains. For each polar expression, the annotation includes the **expression itself**, the **target** (i.e., the object of the sentiment), and the **source** (i.e., the subject expressing the sentiment). In total, 25,453 polar expressions have been annotated.\n",
    "\n",
    "**Access:** [projecte-aina/CaSSA on Hugging Face](https://huggingface.co/datasets/projecte-aina/CaSSA-catalan-structured-sentiment-analysis)\n",
    "\n",
    "**Source:** Aina Project\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "Each instance in the dataset is a text. For each text, there can be 0 to unlimited polar expressions, which are contained in the \"opinions\" field. Each opinion contains a source, a target, a polar expression, a polarity value and an intensity value.\n",
    "\n",
    "To convert this structured information into a single sentiment label per text, we apply the following strategy:\n",
    "- Count all Positive, Negative, and Neutral polarities per opinion.\n",
    "- Assign the sentiment label based on the dominant polarity.\n",
    "  - If Positive polar expressions are the majority: **Positive**.\n",
    "  - If Negative polar expressions dominate: **Negative**.\n",
    "  - In case of a tie or no polar expressions: **Neutral**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ff72189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 218.60ba/s]\n",
      "Creating CSV from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 271.23ba/s]\n",
      "Creating CSV from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 282.43ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'text': \"IE TIO!! MOLT BONA INICIATIVA!! A MI DE VEGADES TAMB√â EM VENEN GANES DE CANVIAR-LOS, PER√í, COM LA MAJORIA,MAI M'HE DECIDIT A FER-HO. POT SE ARA JA M'HO PLANTEGE MILLOR....\\n\", 'label': 'positive'}\n",
      "Validation: {'text': 'Dels pocs llocs del Ripoll√®s on trobar√†s bin peix. Aqu√≠ el trobar√†s b√≤ i barat.', 'label': 'positive'}\n",
      "Test: {'text': \"Que n'havia fet jo de cassera de dracs amb pals ben llargs per les parets del poble de El Mil√† per les nits d'estiu de fa anys... H√≤stia, que bo, he trobat una fotografia realment bona. Una vista del poble de El Mil√† on es veu la casa que tenia ara fa uns anys la meva fam√≠lia, amb el tros i tot!!!! Que abandonat que el tenen el tros?!?! Hi ha alg√∫ per ac√≠ de El Mil√† o voltants?\\n\", 'label': 'neutral'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds_cassa = load_dataset(\"projecte-aina/CaSSA-catalan-structured-sentiment-analysis\")[\"train\"]\n",
    "\n",
    "def relabel_from_opinions(item):\n",
    "    pos = neg = neu = 0\n",
    "\n",
    "    for opinion in item.get(\"opinions\", []):\n",
    "        polarity = opinion.get(\"Polarity\")\n",
    "\n",
    "        if isinstance(polarity, str):\n",
    "            polarity = polarity.strip().lower()\n",
    "\n",
    "            if polarity == \"positive\":\n",
    "                pos += 1\n",
    "            elif polarity == \"negative\":\n",
    "                neg += 1\n",
    "            elif polarity == \"neutral\":\n",
    "                neu += 1\n",
    "\n",
    "    if pos > neg and pos > neu:\n",
    "        label = \"positive\"\n",
    "    elif neg > pos and neg > neu:\n",
    "        label = \"negative\"\n",
    "    else:\n",
    "        label = \"neutral\"\n",
    "\n",
    "    return {\"text\": item[\"text\"], \"label\": label}\n",
    "\n",
    "ds_cassa_labeled = ds_cassa.map(relabel_from_opinions)\n",
    "\n",
    "ds_split = ds_cassa_labeled.train_test_split(test_size=0.2, seed=42)\n",
    "ds_val_test = ds_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "ds_cassa_clean = {\n",
    "    \"train\": ds_split[\"train\"],\n",
    "    \"validation\": ds_val_test[\"train\"],\n",
    "    \"test\": ds_val_test[\"test\"]\n",
    "}\n",
    "\n",
    "for split in ds_cassa_clean:\n",
    "    keep = [\"text\", \"label\"]\n",
    "    drop = [col for col in ds_cassa_clean[split].column_names if col not in keep]\n",
    "    ds_cassa_clean[split] = ds_cassa_clean[split].remove_columns(drop)\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    os.makedirs(split, exist_ok=True)\n",
    "    output_path = os.path.join(split, \"cassa.csv\")\n",
    "    ds_cassa_clean[split].to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Train:\", ds_cassa_clean[\"train\"][0])\n",
    "print(\"Validation:\", ds_cassa_clean[\"validation\"][0])\n",
    "print(\"Test:\", ds_cassa_clean[\"test\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f160c64",
   "metadata": {},
   "source": [
    "## 3. GoEmotions Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0b3514",
   "metadata": {},
   "source": [
    "**Description:** The GoEmotions dataset is a large-scale human-annotated corpus of 58k English Reddit comments labeled for 27 emotion categories plus neutral. It was developed by Google AI to support fine-grained sentiment and emotion classification in user-generated content. Each comment may be associated with one or multiple emotion labels, making it suitable for multilabel classification tasks.\n",
    "\n",
    "**Access:** [https://www.kaggle.com/datasets/debarshichanda/goemotions](https://www.kaggle.com/datasets/debarshichanda/goemotions)\n",
    "\n",
    "**Source:**  Google AI\n",
    "\n",
    "**Notes:**  \n",
    "- The GoEmotions dataset includes annotations for 27 fine-grained emotion categories plus a neutral class. Since each Reddit comment can be associated with **multiple emotions**, we adopt a two-step strategy to simplify the dataset into three general sentiment categories: **Positive**, **Negative**, and **Neutral**.\n",
    "\n",
    "- In the **first step**, each emotion label is mapped to one of three broader sentiment groups:\n",
    "\n",
    "  - **Positive**: amusement, excitement, joy, love, desire, optimism, caring, pride, admiration, gratitude, relief, approval.\n",
    "  \n",
    "  - **Negative**: fear, nervousness, remorse, embarrassment, disappointment, sadness, grief, disgust, anger, annoyance, disapproval.\n",
    "  \n",
    "  - **Ambiguous**: realization, surprise, curiosity, confusion.\n",
    "\n",
    "- In the **second step**, we count how many mapped emotions of each type are assigned to a given comment, and apply the following decision rule:\n",
    "\n",
    "  - If **Positive** emotions are the majority: classify as **Positive**.  \n",
    "  - If **Negative** emotions are the majority: classify as **Negative**.  \n",
    "  - If there is a tie or no mapped emotions: classify as **Neutral**.\n",
    "\n",
    "This strategy allows us to transform a complex multilabel emotion task into a simpler, interpretable sentiment classification problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a66ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12898/948054610.py:22: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  hf_ds = kagglehub.load_dataset(\n",
      "Fetching 6 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 93206.76it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/tmp/ipykernel_12898/948054610.py:46: DeprecationWarning: Reading the TranslationResult object as a list of dictionaries is deprecated and will be removed in a future version. Please use the object attributes as described in the documentation: https://opennmt.net/CTranslate2/python/ctranslate2.TranslationResult.html\n",
      "  return sp.decode(translation[0][0][\"tokens\"])\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:59<00:00,  1.69it/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 19798.46 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example samples:\n",
      "\n",
      "[1] EN: Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead\n",
      "    CA: Ara b√©, si es treu a si mateix, tothom pensar√† que riu fotent-se de la gent en lloc de realment mort\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[2] EN: WHY THE FUCK IS BAYLESS ISOING\n",
      "    CA: PER QU√à LA MERDA √âS AIX√í SENSE BAYLESS\n",
      "    Emotions: ['anger']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[3] EN: To make her feel threatened\n",
      "    CA: Perqu√® se senti amena√ßada\n",
      "    Emotions: ['fear']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[4] EN: Dirty Southern Wankers\n",
      "    CA: brutes del sud Wankers\n",
      "    Emotions: ['annoyance']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[5] EN: OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe PlAyOfFs! Dumbass Broncos fans circa December 2015.\n",
      "    CA: OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe PlAyOfFs! Tontos fans dels Broncs al voltant de desembre de 2015.\n",
      "    Emotions: ['surprise']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[6] EN: Yes I heard abt the f bombs! That has to be why. Thanks for your reply:) until then hubby and I will anxiously wait üòù\n",
      "    CA: S√≠, he sentit a parlar de les bombes f! Aix√≤ ha de ser per aix√≤. Gr√†cies per la seva resposta:) fins llavors maridito i jo esperar√© ansiosament  ‚Åá \n",
      "    Emotions: ['gratitude']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[7] EN: We need more boards and to create a bit more space for [NAME]. Then we‚Äôll be good.\n",
      "    CA: Necessitem m√©s taulers i crear una mica m√©s d'espai per a [NOM]. Llavors estarem b√©.\n",
      "    Emotions: ['desire', 'optimism']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[8] EN: Damn youtube and outrage drama is super lucrative for reddit\n",
      "    CA: Male√Øt youtube i el drama de la indignaci√≥ √©s s√∫per lucratiu per a reddit\n",
      "    Emotions: ['admiration']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[9] EN: It might be linked to the trust factor of your friend.\n",
      "    CA: Pot estar relacionat amb el factor de confian√ßa del teu amic.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[10] EN: Demographics? I don‚Äôt know anybody under 35 who has cable tv.\n",
      "    CA: Demografia? No conec ning√∫ menor de 35 anys que tingui televisi√≥ per cable.\n",
      "    Emotions: ['confusion']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[11] EN: Aww... she'll probably come around eventually, I'm sure she was just jealous of [NAME]... I mean, what woman wouldn't be! lol \n",
      "    CA: Aww... ella probablement vindr√† per aqu√≠ eventualment, estic segur que nom√©s estava gelosa de [NOM]... Vull dir, quina dona no seria! lol\n",
      "    Emotions: ['amusement', 'approval']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[12] EN: Hello everyone. Im from Toronto as well. Can call and visit in personal if needed.\n",
      "    CA: Hola a tots. S√≥c de Toronto, aix√≠. Pot trucar i visitar en personal si √©s necessari.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[13] EN: R/sleeptrain Might be time for some sleep training. Take a look and try to feel out what's right for your family.\n",
      "    CA: R /sleeptrain Pot ser el moment d'una mica d'entrenament per dormir. Fer una ullada i tractar de sentir el que √©s adequat per a la seva fam√≠lia.\n",
      "    Emotions: ['caring']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[14] EN: [NAME] - same fucking problem, slightly better command of the English language.\n",
      "    CA: [NOM] - el mateix male√Øt problema, un domini lleugerament millor de l'idioma angl√®s.\n",
      "    Emotions: ['annoyance']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[15] EN: Shit, I guess I accidentally bought a Pay-Per-View boxing match\n",
      "    CA: Merda, suposo que accidentalment vaig comprar un f√≤sfor de boxa Pay-Per-View\n",
      "    Emotions: ['annoyance', 'embarrassment']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[16] EN: Thank you friend\n",
      "    CA: Gr√†cies amic\n",
      "    Emotions: ['gratitude']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[17] EN: Fucking coward.\n",
      "    CA: Male√Øt covard.\n",
      "    Emotions: ['anger']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[18] EN: that is what retardation looks like\n",
      "    CA: aix√≠ √©s el retard\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[19] EN: Maybe that‚Äôs what happened to the great white at Houston zoo\n",
      "    CA: Potser aix√≤ √©s el que li va passar al gran blanc al zoo de Houston\n",
      "    Emotions: ['confusion', 'realization']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[20] EN: I never thought it was at the same moment, but sometimes after [NAME] sacrifice... sounds logical\n",
      "    CA: Mai vaig pensar que fos en el mateix moment, per√≤ de vegades despr√©s de [NOM] sacrifici... sona l√≤gic\n",
      "    Emotions: ['confusion', 'disappointment', 'neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[21] EN: i got a bump and a bald spot. i feel dumb <3\n",
      "    CA: tinc un bony i una calba. em sento ximple <3\n",
      "    Emotions: ['embarrassment']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[22] EN: You are going to do the dishes now\n",
      "    CA: Ara rentar√†s els plats\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[23] EN: Slowing things down now\n",
      "    CA: Ara s'estan alentint les coses\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[24] EN: His name has already been released. Just can't post it here.\n",
      "    CA: El seu nom ja ha estat alliberat. No el puc publicar aqu√≠.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[25] EN: Stupidly stubborn / stubbornly stupid\n",
      "    CA: Est√∫pidament tossut / obstinadament est√∫pid\n",
      "    Emotions: ['anger']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[26] EN: Mine was apparently [NAME] and the giant peach!\n",
      "    CA: El meu era aparentment [NOM] i el pr√©ssec gegant!\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[27] EN: I miss them being alive\n",
      "    CA: Trobo a faltar que estiguin vius\n",
      "    Emotions: ['grief', 'sadness']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[28] EN: Super, thanks\n",
      "    CA: Super, gr√†cies\n",
      "    Emotions: ['gratitude']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[29] EN: A new study just came out from China that it's actually too late.\n",
      "    CA: Acaba de sortir un nou estudi de la Xina que en realitat √©s massa tard.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[30] EN: Troll, bro. They know they're saying stupid shit. The motherfucker does nothing but stink up libertarian subs talking shit\n",
      "    CA: Troll, germ√†. Saben que estan dient ximpleries. El fill de puta no fa res m√©s que fer pudor els subs llibertaris parlant merda\n",
      "    Emotions: ['anger']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[31] EN: All sounds possible except the key, I can't see how it was missed in the first search. \n",
      "    CA: Tots els sons possibles excepte la clau, no puc veure com es va perdre a la primera cerca.\n",
      "    Emotions: ['confusion']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[32] EN: Your aunt has some damn nerve, though!\n",
      "    CA: Per√≤ la teva tia t√© una mica de nervi!\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[33] EN: Ok, then what the actual fuck is your plan?\n",
      "    CA: Ok, llavors quin carall √©s el teu pla?\n",
      "    Emotions: ['anger', 'curiosity']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[34] EN: What does FPTP have to do with the referendum?\n",
      "    CA: Qu√® t√© a veure FPTP amb el refer√®ndum?\n",
      "    Emotions: ['confusion']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[35] EN: Happy to be able to help.\n",
      "    CA: Feli√ß de poder ajudar.\n",
      "    Emotions: ['joy']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[36] EN: 18 is hot but very bland, it's just here this blonde lady who is not as hot as blonde launch.\n",
      "    CA: 18 √©s calent per√≤ molt ins√≠pid, nom√©s √©s aqu√≠ aquesta senyora rossa que no √©s tan calenta com rossa llan√ßament.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[37] EN: Famous for his 3-4 Defense\n",
      "    CA: Fam√≥s per la seva defensa 3-4\n",
      "    Emotions: ['admiration']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[38] EN: Pretty sure I‚Äôve seen this. He swings away with the harness he is wearing. Still looks painful but I think he lives\n",
      "    CA: Bastant segur que he vist aix√≤. Es balanceja amb l'arn√®s que porta. Encara es veu dolor√≥s, per√≤ crec que viu\n",
      "    Emotions: ['sadness']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[39] EN: When I feel down I listen to music.\n",
      "    CA: Quan em sento deprimit escolto m√∫sica.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[40] EN: aw, thanks! I appreciate that! \n",
      "    CA: aw, gr√†cies! T'ho agraeixo!\n",
      "    Emotions: ['admiration', 'gratitude']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[41] EN: Thanks! I love watching him every week\n",
      "    CA: Gr√†cies. M'encanta veure' l cada setmana\n",
      "    Emotions: ['gratitude', 'love']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[42] EN: I read on a different post that he died shortly after of internal injuries.\n",
      "    CA: He llegit en un altre post que va morir poc despr√©s per ferides internes.\n",
      "    Emotions: ['grief', 'neutral']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[43] EN: Honestly it sounds exhausting being married to him. Maybe it will be better for you in the long run.\n",
      "    CA: Honestament, sona esgotador estar casat amb ell. Potser ser√† millor per a tu a llarg termini.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[44] EN: It's crazy how far Photoshop has come. Underwater bridges?!! NEVER!!!\n",
      "    CA: √âs una bogeria el lluny que ha arribat Photoshop. Ponts submarins?!! MAI!!!\n",
      "    Emotions: ['curiosity', 'excitement']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[45] EN: I wouldn't let a sweet potato dictate decisions, ever.\n",
      "    CA: Jo no deixaria que una batata dict√©s decisions, mai.\n",
      "    Emotions: ['disapproval']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[46] EN: It's true though. He either gets no shirt and freezes to death or wears a stupid looking butchers cape. I hope he gets something better next season\n",
      "    CA: √âs cert, per√≤. O no aconsegueix camisa i es congela fins a la mort o porta una capa de carnisser d'aspecte est√∫pid. Espero que aconsegueixi alguna cosa millor la temporada que\n",
      "    Emotions: ['optimism']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[47] EN: It's a better option because it's my life and none of your business? Lmfao, who are you\n",
      "    CA: √âs una millor opci√≥ perqu√® √©s la meva vida i no √©s assumpte teu? Lmfao, qui ets\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[48] EN: Sack, shaft, and tip. The trifecta. \n",
      "    CA: Sac, eix i punta. La trifecta.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[49] EN: I know. My question was if they **used** to compete in T5-TTT2.\n",
      "    CA: Ho s√©. La meva pregunta era si **utilitzaven** per competir en T5-TTT2.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[50] EN: FBI!! OPEN UP!!!\n",
      "    CA: FBI!! OBRIR!!!\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 477.44ba/s]\n",
      "Creating CSV from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 981.12ba/s]\n",
      "Creating CSV from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 1591.77ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Script finished and files saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "for package in [\"ctranslate2\", \"sentencepiece\", \"kagglehub[hf-datasets]\", \"datasets\", \"tqdm\", \"huggingface_hub\"]:\n",
    "    pkg_name = package.split(\"[\")[0] if \"[\" in package else package\n",
    "    try:\n",
    "        __import__(pkg_name)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from huggingface_hub import snapshot_download\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "import ctranslate2\n",
    "import sentencepiece as spm\n",
    "\n",
    "file_path = \"data/train.tsv\"\n",
    "hf_ds = kagglehub.load_dataset(\n",
    "    KaggleDatasetAdapter.HUGGING_FACE,\n",
    "    \"debarshichanda/goemotions\",\n",
    "    file_path,\n",
    "    pandas_kwargs={\n",
    "        \"sep\": \"\\t\",\n",
    "        \"names\": [\"text_en\", \"labels\", \"id\"],\n",
    "        \"header\": 0\n",
    "    }\n",
    ")\n",
    "hf_ds = hf_ds.remove_columns(\"id\")\n",
    "hf_ds = hf_ds.select(range(10000))\n",
    "\n",
    "model_dir = snapshot_download(repo_id=\"projecte-aina/aina-translator-en-ca\", revision=\"main\")\n",
    "sp_model_path = os.path.join(model_dir, \"spm.model\")\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(sp_model_path)\n",
    "translator = ctranslate2.Translator(model_dir)\n",
    "\n",
    "def translate_en_to_ca(text):\n",
    "    try:\n",
    "        tokens = sp.encode(text, out_type=str)\n",
    "        translation = translator.translate_batch([tokens])\n",
    "        return sp.decode(translation[0][0][\"tokens\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {text[:50]}... ‚Üí {e}\")\n",
    "        return \"\"\n",
    "\n",
    "tqdm.pandas()\n",
    "df = hf_ds.to_pandas()\n",
    "df[\"text\"] = df[\"text_en\"].progress_apply(translate_en_to_ca)\n",
    "\n",
    "\n",
    "hf_ds = Dataset.from_pandas(df)\n",
    "\n",
    "def parse_labels(labels_str):\n",
    "\n",
    "    if isinstance(labels_str, list):\n",
    "        return labels_str\n",
    "    if isinstance(labels_str, int):\n",
    "        return [labels_str]\n",
    "    \n",
    "    try:\n",
    "        if isinstance(labels_str, str) and labels_str:\n",
    "            return [int(i) for i in labels_str.split(',')]\n",
    "        return []\n",
    "    except (ValueError, TypeError):\n",
    "        return []\n",
    "\n",
    "emotion_id2label = [\n",
    "    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\", \"confusion\",\n",
    "    \"curiosity\", \"desire\", \"disappointment\", \"disapproval\", \"disgust\", \"embarrassment\",\n",
    "    \"excitement\", \"fear\", \"gratitude\", \"grief\", \"joy\", \"love\", \"nervousness\", \"optimism\",\n",
    "    \"pride\", \"realization\", \"relief\", \"remorse\", \"sadness\", \"surprise\", \"neutral\"\n",
    "]\n",
    "\n",
    "sentiment_map = {\n",
    "    \"positive\": {\"amusement\", \"excitement\", \"joy\", \"love\", \"desire\", \"optimism\", \"caring\",\n",
    "                 \"pride\", \"admiration\", \"gratitude\", \"relief\", \"approval\"},\n",
    "    \"negative\": {\"fear\", \"nervousness\", \"remorse\", \"embarrassment\", \"disappointment\",\n",
    "                 \"sadness\", \"grief\", \"disgust\", \"anger\", \"annoyance\", \"disapproval\"},\n",
    "    \"ambiguous\": {\"realization\", \"surprise\", \"curiosity\", \"confusion\"}\n",
    "}\n",
    "\n",
    "def classify_sentiment(emotion_ids):\n",
    "    \"\"\"Clasifica el sentimiento basado en una lista de IDs de emoci√≥n.\"\"\"\n",
    "    counts = {\"positive\": 0, \"negative\": 0, \"ambiguous\": 0}\n",
    "\n",
    "    for eid in emotion_ids:\n",
    "        if isinstance(eid, int) and eid < len(emotion_id2label):\n",
    "            emotion = emotion_id2label[eid]\n",
    "            for category in sentiment_map:\n",
    "                if emotion in sentiment_map[category]:\n",
    "                    counts[category] += 1\n",
    "                    break\n",
    "    if counts[\"positive\"] > counts[\"negative\"] and counts[\"positive\"] > counts[\"ambiguous\"]:\n",
    "        return \"positive\"\n",
    "    elif counts[\"negative\"] > counts[\"positive\"] and counts[\"negative\"] > counts[\"ambiguous\"]:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "def process_and_classify(example):\n",
    "    parsed_labels = parse_labels(example[\"labels\"])\n",
    "    return {\n",
    "        \"labels\": parsed_labels,\n",
    "        \"label\": classify_sentiment(parsed_labels)\n",
    "    }\n",
    "\n",
    "hf_ds = hf_ds.map(process_and_classify)\n",
    "\n",
    "print(\"\\nExample samples:\\n\")\n",
    "for i in range(50):\n",
    "    row = hf_ds[i]\n",
    "    emotions = [emotion_id2label[e] for e in row[\"labels\"]]\n",
    "    print(f\"[{i+1}] EN: {row['text_en']}\")\n",
    "    print(f\"    CA: {row['text']}\")\n",
    "    print(f\"    Emotions: {emotions}\")\n",
    "    print(f\"    Sentiment: {row['label']}\")\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "hf_ds = hf_ds.remove_columns([\"labels\", \"text_en\"])\n",
    "ds_split = hf_ds.train_test_split(test_size=0.2, seed=42)\n",
    "ds_val_test = ds_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "ds_goemotions_clean = {\n",
    "    \"train\": ds_split[\"train\"],\n",
    "    \"validation\": ds_val_test[\"train\"],\n",
    "    \"test\": ds_val_test[\"test\"]\n",
    "}\n",
    "\n",
    "for split in ds_goemotions_clean:\n",
    "    keep = [\"text\", \"label\"]\n",
    "    drop = [col for col in ds_goemotions_clean[split].column_names if col not in keep]\n",
    "    ds_goemotions_clean[split] = ds_goemotions_clean[split].remove_columns(drop)\n",
    "\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    os.makedirs(split, exist_ok=True)\n",
    "    output_path = os.path.join(split, \"goemotions.csv\")\n",
    "    ds_goemotions_clean[split].to_csv(output_path, index=False)\n",
    "\n",
    "print(\"\\nScript finished and files saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b390fba",
   "metadata": {},
   "source": [
    "## 4. Create the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ff359d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 'train' folder with 3 CSV files...\n",
      "Saved combined CSV to: /home/user/Escritorio/TFM/train/train.csv\n",
      "\n",
      "Processing 'validation' folder with 3 CSV files...\n",
      "Saved combined CSV to: /home/user/Escritorio/TFM/validation/validation.csv\n",
      "\n",
      "Processing 'test' folder with 3 CSV files...\n",
      "Saved combined CSV to: /home/user/Escritorio/TFM/test/test.csv\n",
      "\n",
      "Final dataset row counts:\n",
      "- train: 9950 rows\n",
      "- validation: 1150 rows\n",
      "- test: 1150 rows\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "splits = [\"train\", \"validation\", \"test\"]\n",
    "expected_columns = [\"text\", \"label\"]\n",
    "row_counts = {}\n",
    "\n",
    "for split in splits:\n",
    "    folder_path = os.path.abspath(split)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    all_csvs = [os.path.join(folder_path, f) for f in os.listdir(folder_path)\n",
    "                if f.endswith(\".csv\") and f != f\"{split}.csv\"]  # Skip previous output if re-run\n",
    "\n",
    "    if not all_csvs:\n",
    "        print(f\"No CSV files found in: {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing '{split}' folder with {len(all_csvs)} CSV files...\")\n",
    "\n",
    "    dfs = []\n",
    "    for csv_file in all_csvs:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            if set(df.columns) != set(expected_columns):\n",
    "                print(f\"Skipping {csv_file} (columns mismatch: found {list(df.columns)})\")\n",
    "                continue\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {csv_file}: {e}\")\n",
    "\n",
    "    if dfs:\n",
    "        combined = pd.concat(dfs, ignore_index=True)\n",
    "        row_counts[split] = len(combined)\n",
    "\n",
    "        output_path = os.path.join(folder_path, f\"{split}.csv\")\n",
    "        combined.to_csv(output_path, index=False)\n",
    "        print(f\"Saved combined CSV to: {output_path}\")\n",
    "    else:\n",
    "        print(f\"No valid CSV files to combine in: {folder_path}\")\n",
    "        row_counts[split] = 0\n",
    "\n",
    "\n",
    "print(\"\\nFinal dataset row counts:\")\n",
    "for split in splits:\n",
    "    print(f\"- {split}: {row_counts.get(split, 0)} rows\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
