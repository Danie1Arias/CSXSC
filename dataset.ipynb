{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f444ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1fc6f3",
   "metadata": {},
   "source": [
    "# Classificador de Sentiments a Xarxes Socials en Català (CSXSC): Dataset\n",
    "\n",
    "**Author:** Daniel Arias Cámara  \n",
    "**Date:** 25-07-2025  \n",
    "\n",
    "**Description:**  This notebook aims to build a high-quality dataset for fine-tuning the **CSXSC** model. The dataset is constructed by combining trusted data sources, including structured sentiment corpora and translated social media content. Details on data origin and preprocessing steps are provided in the sections below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfd3695",
   "metadata": {},
   "source": [
    "## 1. GuiaCat Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902f794",
   "metadata": {},
   "source": [
    "**Description:** This dataset consists of 5,750 restaurant reviews in Catalan, sourced from the GuiaCat platform. Each review includes individual ratings for service, food, price-quality ratio, and atmosphere, along with an overall average score.\n",
    "\n",
    "**Access:** [projecte-aina/GuiaCat on Hugging Face](https://huggingface.co/datasets/projecte-aina/GuiaCat)\n",
    "\n",
    "**Source:** Aina Project\n",
    "\n",
    "**Notes:**  \n",
    "The dataset is divided into three subsets:  \n",
    "- **Train:** 1,750 rows  \n",
    "- **Validation:** 500 rows  \n",
    "- **Test:** 500 rows  \n",
    "\n",
    "The original fields are: Service, Food, Price-quality, Environment, Avg, Text, and Label.  \n",
    "For our purposes, we retain only the Text and Label fields, discarding the rest.\n",
    "\n",
    "The Label field includes five sentiment categories:  \n",
    "- Molt bo (Very good)  \n",
    "- Bo (Good)  \n",
    "- Regular (Average)  \n",
    "- Dolent (Bad)  \n",
    "- Molt dolent (Very bad)\n",
    "\n",
    "These are grouped into three classes for sentiment classification:  \n",
    "- **Positive:** Molt bo and Bo  \n",
    "- **Neutral:** Regular  \n",
    "- **Negative:** Dolent and Molt dolent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d57d28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 316.32ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 401.64ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 424.27ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'text': 'El lloc és acollidor. El tracte, familiar. Els plats són casolans, abundants i de qualitat! Productes de la terra com embutits i altres de la zona. Hi tornarem segur!', 'label': 'positive'}\n",
      "Validation: {'text': 'Bon Menjar i bon tracte en un restaurant que segú hi tornaràs un altre vegada.', 'label': 'positive'}\n",
      "Test: {'text': \"Fantàstic restaurant ,una carta plena de plats creatius i cuina de temporada que sempre es d'agrair , i el que varem menjar nosaltres molt bé, estic segura que tornaré no ho dubtaré.El tracte bó i l'espai molt acollidor.\", 'label': 'positive'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    import datasets\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"-q\", \"datasets\"])\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds_guiacat = load_dataset(\"projecte-aina/GuiaCat\")\n",
    "ds = {}\n",
    "\n",
    "for split in ds_guiacat:\n",
    "    drop_columns = [col for col in ds_guiacat[split].column_names if col not in [\"text\", \"label\"]]\n",
    "    ds[split] = ds_guiacat[split].remove_columns(drop_columns)\n",
    "\n",
    "    def relabel(opinion):\n",
    "        label = opinion[\"label\"].lower()\n",
    "        if label in [\"molt bo\", \"bo\"]:\n",
    "            opinion[\"label\"] = \"positive\"\n",
    "        elif label == \"regular\":\n",
    "            opinion[\"label\"] = \"neutral\"\n",
    "        elif label in [\"dolent\", \"molt dolent\"]:\n",
    "            opinion[\"label\"] = \"negative\"\n",
    "        return opinion\n",
    "\n",
    "    ds[split] = ds[split].map(relabel)\n",
    "\n",
    "output_dirs = {\n",
    "    \"train\": \"train\",\n",
    "    \"validation\": \"validate\",\n",
    "    \"test\": \"test\"\n",
    "}\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    os.makedirs(split, exist_ok=True)\n",
    "    output_path = os.path.join(split, \"guiacat.csv\")\n",
    "    ds[split].to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Train:\", ds[\"train\"][0])\n",
    "print(\"Validation:\", ds[\"validation\"][0])\n",
    "print(\"Test:\", ds[\"test\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6754525",
   "metadata": {},
   "source": [
    "## 2. Catalan Structured Sentiment Analysis (CaSSA) Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1631b602",
   "metadata": {},
   "source": [
    "**Description:** The CaSSA dataset contains 6,400 reviews and forum messages in Catalan, annotated at the fine-grained level with polar expressions. Each text instance is labeled with all the sentiment expressions it contains. For each polar expression, the annotation includes the **expression itself**, the **target** (i.e., the object of the sentiment), and the **source** (i.e., the subject expressing the sentiment). In total, 25,453 polar expressions have been annotated.\n",
    "\n",
    "**Access:** [projecte-aina/CaSSA on Hugging Face](https://huggingface.co/datasets/projecte-aina/CaSSA-catalan-structured-sentiment-analysis)\n",
    "\n",
    "**Source:** Aina Project\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "Each instance in the dataset is a text. For each text, there can be 0 to unlimited polar expressions, which are contained in the \"opinions\" field. Each opinion contains a source, a target, a polar expression, a polarity value and an intensity value.\n",
    "\n",
    "To convert this structured information into a single sentiment label per text, we apply the following strategy:\n",
    "- Count all Positive, Negative, and Neutral polarities per opinion.\n",
    "- Assign the sentiment label based on the dominant polarity.\n",
    "  - If Positive polar expressions are the majority: **Positive**.\n",
    "  - If Negative polar expressions dominate: **Negative**.\n",
    "  - In case of a tie or no polar expressions: **Neutral**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ff72189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 164.66ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 196.22ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 199.90ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'text': \"IE TIO!! MOLT BONA INICIATIVA!! A MI DE VEGADES TAMBÉ EM VENEN GANES DE CANVIAR-LOS, PERÒ, COM LA MAJORIA,MAI M'HE DECIDIT A FER-HO. POT SE ARA JA M'HO PLANTEGE MILLOR....\\n\", 'label': 'positive'}\n",
      "Validation: {'text': 'Dels pocs llocs del Ripollès on trobaràs bin peix. Aquí el trobaràs bò i barat.', 'label': 'positive'}\n",
      "Test: {'text': \"Que n'havia fet jo de cassera de dracs amb pals ben llargs per les parets del poble de El Milà per les nits d'estiu de fa anys... Hòstia, que bo, he trobat una fotografia realment bona. Una vista del poble de El Milà on es veu la casa que tenia ara fa uns anys la meva família, amb el tros i tot!!!! Que abandonat que el tenen el tros?!?! Hi ha algú per ací de El Milà o voltants?\\n\", 'label': 'neutral'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds_cassa = load_dataset(\"projecte-aina/CaSSA-catalan-structured-sentiment-analysis\")[\"train\"]\n",
    "\n",
    "def relabel_from_opinions(item):\n",
    "    pos = neg = neu = 0\n",
    "\n",
    "    for opinion in item.get(\"opinions\", []):\n",
    "        polarity = opinion.get(\"Polarity\")\n",
    "\n",
    "        if isinstance(polarity, str):\n",
    "            polarity = polarity.strip().lower()\n",
    "\n",
    "            if polarity == \"positive\":\n",
    "                pos += 1\n",
    "            elif polarity == \"negative\":\n",
    "                neg += 1\n",
    "            elif polarity == \"neutral\":\n",
    "                neu += 1\n",
    "\n",
    "    if pos > neg and pos > neu:\n",
    "        label = \"positive\"\n",
    "    elif neg > pos and neg > neu:\n",
    "        label = \"negative\"\n",
    "    else:\n",
    "        label = \"neutral\"\n",
    "\n",
    "    return {\"text\": item[\"text\"], \"label\": label}\n",
    "\n",
    "ds_cassa_labeled = ds_cassa.map(relabel_from_opinions)\n",
    "\n",
    "ds_split = ds_cassa_labeled.train_test_split(test_size=0.2, seed=42)\n",
    "ds_val_test = ds_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "ds_cassa_clean = {\n",
    "    \"train\": ds_split[\"train\"],\n",
    "    \"validation\": ds_val_test[\"train\"],\n",
    "    \"test\": ds_val_test[\"test\"]\n",
    "}\n",
    "\n",
    "for split in ds_cassa_clean:\n",
    "    keep = [\"text\", \"label\"]\n",
    "    drop = [col for col in ds_cassa_clean[split].column_names if col not in keep]\n",
    "    ds_cassa_clean[split] = ds_cassa_clean[split].remove_columns(drop)\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    os.makedirs(split, exist_ok=True)\n",
    "    output_path = os.path.join(split, \"cassa.csv\")\n",
    "    ds_cassa_clean[split].to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Train:\", ds_cassa_clean[\"train\"][0])\n",
    "print(\"Validation:\", ds_cassa_clean[\"validation\"][0])\n",
    "print(\"Test:\", ds_cassa_clean[\"test\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
