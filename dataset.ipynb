{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f444ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1fc6f3",
   "metadata": {},
   "source": [
    "# Classificador de Sentiments a Xarxes Socials en Català (CSXSC): Dataset\n",
    "\n",
    "**Author:** Daniel Arias Cámara  \n",
    "**Date:** 25-07-2025  \n",
    "\n",
    "**Description:**  This notebook aims to build a high-quality dataset for fine-tuning the **CSXSC** model. The dataset is constructed by combining trusted data sources, including structured sentiment corpora and translated social media content. Details on data origin and preprocessing steps are provided in the sections below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfd3695",
   "metadata": {},
   "source": [
    "## 1. GuiaCat Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902f794",
   "metadata": {},
   "source": [
    "**Description:** This dataset consists of 5,750 restaurant reviews in Catalan, sourced from the GuiaCat platform. Each review includes individual ratings for service, food, price-quality ratio, and atmosphere, along with an overall average score.\n",
    "\n",
    "**Access:** [projecte-aina/GuiaCat on Hugging Face](https://huggingface.co/datasets/projecte-aina/GuiaCat)\n",
    "\n",
    "**Source:** Aina Project\n",
    "\n",
    "**Notes:**  \n",
    "The dataset is divided into three subsets:  \n",
    "- **Train:** 1,750 rows  \n",
    "- **Validation:** 500 rows  \n",
    "- **Test:** 500 rows  \n",
    "\n",
    "The original fields are: Service, Food, Price-quality, Environment, Avg, Text, and Label.  \n",
    "For our purposes, we retain only the Text and Label fields, discarding the rest.\n",
    "\n",
    "The Label field includes five sentiment categories:  \n",
    "- Molt bo (Very good)  \n",
    "- Bo (Good)  \n",
    "- Regular (Average)  \n",
    "- Dolent (Bad)  \n",
    "- Molt dolent (Very bad)\n",
    "\n",
    "These are grouped into three classes for sentiment classification:  \n",
    "- **Positive:** Molt bo and Bo  \n",
    "- **Neutral:** Regular  \n",
    "- **Negative:** Dolent and Molt dolent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d57d28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/ai/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Creating CSV from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 286.28ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 529.52ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 532.14ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'text': 'El lloc és acollidor. El tracte, familiar. Els plats són casolans, abundants i de qualitat! Productes de la terra com embutits i altres de la zona. Hi tornarem segur!', 'label': 'positive'}\n",
      "Validation: {'text': 'Bon Menjar i bon tracte en un restaurant que segú hi tornaràs un altre vegada.', 'label': 'positive'}\n",
      "Test: {'text': \"Fantàstic restaurant ,una carta plena de plats creatius i cuina de temporada que sempre es d'agrair , i el que varem menjar nosaltres molt bé, estic segura que tornaré no ho dubtaré.El tracte bó i l'espai molt acollidor.\", 'label': 'positive'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    import datasets\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"-q\", \"datasets\"])\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds_guiacat = load_dataset(\"projecte-aina/GuiaCat\")\n",
    "ds = {}\n",
    "\n",
    "for split in ds_guiacat:\n",
    "    drop_columns = [col for col in ds_guiacat[split].column_names if col not in [\"text\", \"label\"]]\n",
    "    ds[split] = ds_guiacat[split].remove_columns(drop_columns)\n",
    "\n",
    "    def relabel(opinion):\n",
    "        label = opinion[\"label\"].lower()\n",
    "        if label in [\"molt bo\", \"bo\"]:\n",
    "            opinion[\"label\"] = \"positive\"\n",
    "        elif label == \"regular\":\n",
    "            opinion[\"label\"] = \"neutral\"\n",
    "        elif label in [\"dolent\", \"molt dolent\"]:\n",
    "            opinion[\"label\"] = \"negative\"\n",
    "        return opinion\n",
    "\n",
    "    ds[split] = ds[split].map(relabel)\n",
    "\n",
    "output_dirs = {\n",
    "    \"train\": \"train\",\n",
    "    \"validation\": \"validate\",\n",
    "    \"test\": \"test\"\n",
    "}\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    os.makedirs(split, exist_ok=True)\n",
    "    output_path = os.path.join(split, \"guiacat.csv\")\n",
    "    ds[split].to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Train:\", ds[\"train\"][0])\n",
    "print(\"Validation:\", ds[\"validation\"][0])\n",
    "print(\"Test:\", ds[\"test\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6754525",
   "metadata": {},
   "source": [
    "## 2. Catalan Structured Sentiment Analysis (CaSSA) Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1631b602",
   "metadata": {},
   "source": [
    "**Description:** The CaSSA dataset contains 6,400 reviews and forum messages in Catalan, annotated at the fine-grained level with polar expressions. Each text instance is labeled with all the sentiment expressions it contains. For each polar expression, the annotation includes the **expression itself**, the **target** (i.e., the object of the sentiment), and the **source** (i.e., the subject expressing the sentiment). In total, 25,453 polar expressions have been annotated.\n",
    "\n",
    "**Access:** [projecte-aina/CaSSA on Hugging Face](https://huggingface.co/datasets/projecte-aina/CaSSA-catalan-structured-sentiment-analysis)\n",
    "\n",
    "**Source:** Aina Project\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "Each instance in the dataset is a text. For each text, there can be 0 to unlimited polar expressions, which are contained in the \"opinions\" field. Each opinion contains a source, a target, a polar expression, a polarity value and an intensity value.\n",
    "\n",
    "To convert this structured information into a single sentiment label per text, we apply the following strategy:\n",
    "- Count all Positive, Negative, and Neutral polarities per opinion.\n",
    "- Assign the sentiment label based on the dominant polarity.\n",
    "  - If Positive polar expressions are the majority: **Positive**.\n",
    "  - If Negative polar expressions dominate: **Negative**.\n",
    "  - In case of a tie or no polar expressions: **Neutral**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ff72189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 218.60ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 271.23ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 282.43ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'text': \"IE TIO!! MOLT BONA INICIATIVA!! A MI DE VEGADES TAMBÉ EM VENEN GANES DE CANVIAR-LOS, PERÒ, COM LA MAJORIA,MAI M'HE DECIDIT A FER-HO. POT SE ARA JA M'HO PLANTEGE MILLOR....\\n\", 'label': 'positive'}\n",
      "Validation: {'text': 'Dels pocs llocs del Ripollès on trobaràs bin peix. Aquí el trobaràs bò i barat.', 'label': 'positive'}\n",
      "Test: {'text': \"Que n'havia fet jo de cassera de dracs amb pals ben llargs per les parets del poble de El Milà per les nits d'estiu de fa anys... Hòstia, que bo, he trobat una fotografia realment bona. Una vista del poble de El Milà on es veu la casa que tenia ara fa uns anys la meva família, amb el tros i tot!!!! Que abandonat que el tenen el tros?!?! Hi ha algú per ací de El Milà o voltants?\\n\", 'label': 'neutral'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds_cassa = load_dataset(\"projecte-aina/CaSSA-catalan-structured-sentiment-analysis\")[\"train\"]\n",
    "\n",
    "def relabel_from_opinions(item):\n",
    "    pos = neg = neu = 0\n",
    "\n",
    "    for opinion in item.get(\"opinions\", []):\n",
    "        polarity = opinion.get(\"Polarity\")\n",
    "\n",
    "        if isinstance(polarity, str):\n",
    "            polarity = polarity.strip().lower()\n",
    "\n",
    "            if polarity == \"positive\":\n",
    "                pos += 1\n",
    "            elif polarity == \"negative\":\n",
    "                neg += 1\n",
    "            elif polarity == \"neutral\":\n",
    "                neu += 1\n",
    "\n",
    "    if pos > neg and pos > neu:\n",
    "        label = \"positive\"\n",
    "    elif neg > pos and neg > neu:\n",
    "        label = \"negative\"\n",
    "    else:\n",
    "        label = \"neutral\"\n",
    "\n",
    "    return {\"text\": item[\"text\"], \"label\": label}\n",
    "\n",
    "ds_cassa_labeled = ds_cassa.map(relabel_from_opinions)\n",
    "\n",
    "ds_split = ds_cassa_labeled.train_test_split(test_size=0.2, seed=42)\n",
    "ds_val_test = ds_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "ds_cassa_clean = {\n",
    "    \"train\": ds_split[\"train\"],\n",
    "    \"validation\": ds_val_test[\"train\"],\n",
    "    \"test\": ds_val_test[\"test\"]\n",
    "}\n",
    "\n",
    "for split in ds_cassa_clean:\n",
    "    keep = [\"text\", \"label\"]\n",
    "    drop = [col for col in ds_cassa_clean[split].column_names if col not in keep]\n",
    "    ds_cassa_clean[split] = ds_cassa_clean[split].remove_columns(drop)\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    os.makedirs(split, exist_ok=True)\n",
    "    output_path = os.path.join(split, \"cassa.csv\")\n",
    "    ds_cassa_clean[split].to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Train:\", ds_cassa_clean[\"train\"][0])\n",
    "print(\"Validation:\", ds_cassa_clean[\"validation\"][0])\n",
    "print(\"Test:\", ds_cassa_clean[\"test\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f160c64",
   "metadata": {},
   "source": [
    "## 3. GoEmotions Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0b3514",
   "metadata": {},
   "source": [
    "**Description:** The GoEmotions dataset is a large-scale human-annotated corpus of 58k English Reddit comments labeled for 27 emotion categories plus neutral. It was developed by Google AI to support fine-grained sentiment and emotion classification in user-generated content. Each comment may be associated with one or multiple emotion labels, making it suitable for multilabel classification tasks.\n",
    "\n",
    "**Access:** [https://www.kaggle.com/datasets/debarshichanda/goemotions](https://www.kaggle.com/datasets/debarshichanda/goemotions)\n",
    "\n",
    "**Source:**  Google AI\n",
    "\n",
    "**Notes:**  \n",
    "- The GoEmotions dataset includes annotations for 27 fine-grained emotion categories plus a neutral class. Since each Reddit comment can be associated with **multiple emotions**, we adopt a two-step strategy to simplify the dataset into three general sentiment categories: **Positive**, **Negative**, and **Neutral**.\n",
    "\n",
    "- In the **first step**, each emotion label is mapped to one of three broader sentiment groups:\n",
    "\n",
    "  - **Positive**: amusement, excitement, joy, love, desire, optimism, caring, pride, admiration, gratitude, relief, approval.\n",
    "  \n",
    "  - **Negative**: fear, nervousness, remorse, embarrassment, disappointment, sadness, grief, disgust, anger, annoyance, disapproval.\n",
    "  \n",
    "  - **Ambiguous**: realization, surprise, curiosity, confusion.\n",
    "\n",
    "- In the **second step**, we count how many mapped emotions of each type are assigned to a given comment, and apply the following decision rule:\n",
    "\n",
    "  - If **Positive** emotions are the majority: classify as **Positive**.  \n",
    "  - If **Negative** emotions are the majority: classify as **Negative**.  \n",
    "  - If there is a tie or no mapped emotions: classify as **Neutral**.\n",
    "\n",
    "This strategy allows us to transform a complex multilabel emotion task into a simpler, interpretable sentiment classification problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a66ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12898/948054610.py:22: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  hf_ds = kagglehub.load_dataset(\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 93206.76it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/tmp/ipykernel_12898/948054610.py:46: DeprecationWarning: Reading the TranslationResult object as a list of dictionaries is deprecated and will be removed in a future version. Please use the object attributes as described in the documentation: https://opennmt.net/CTranslate2/python/ctranslate2.TranslationResult.html\n",
      "  return sp.decode(translation[0][0][\"tokens\"])\n",
      "100%|██████████| 100/100 [00:59<00:00,  1.69it/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 19798.46 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example samples:\n",
      "\n",
      "[1] EN: Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead\n",
      "    CA: Ara bé, si es treu a si mateix, tothom pensarà que riu fotent-se de la gent en lloc de realment mort\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[2] EN: WHY THE FUCK IS BAYLESS ISOING\n",
      "    CA: PER QUÈ LA MERDA ÉS AIXÒ SENSE BAYLESS\n",
      "    Emotions: ['anger']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[3] EN: To make her feel threatened\n",
      "    CA: Perquè se senti amenaçada\n",
      "    Emotions: ['fear']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[4] EN: Dirty Southern Wankers\n",
      "    CA: brutes del sud Wankers\n",
      "    Emotions: ['annoyance']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[5] EN: OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe PlAyOfFs! Dumbass Broncos fans circa December 2015.\n",
      "    CA: OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe PlAyOfFs! Tontos fans dels Broncs al voltant de desembre de 2015.\n",
      "    Emotions: ['surprise']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[6] EN: Yes I heard abt the f bombs! That has to be why. Thanks for your reply:) until then hubby and I will anxiously wait 😝\n",
      "    CA: Sí, he sentit a parlar de les bombes f! Això ha de ser per això. Gràcies per la seva resposta:) fins llavors maridito i jo esperaré ansiosament  ⁇ \n",
      "    Emotions: ['gratitude']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[7] EN: We need more boards and to create a bit more space for [NAME]. Then we’ll be good.\n",
      "    CA: Necessitem més taulers i crear una mica més d'espai per a [NOM]. Llavors estarem bé.\n",
      "    Emotions: ['desire', 'optimism']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[8] EN: Damn youtube and outrage drama is super lucrative for reddit\n",
      "    CA: Maleït youtube i el drama de la indignació és súper lucratiu per a reddit\n",
      "    Emotions: ['admiration']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[9] EN: It might be linked to the trust factor of your friend.\n",
      "    CA: Pot estar relacionat amb el factor de confiança del teu amic.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[10] EN: Demographics? I don’t know anybody under 35 who has cable tv.\n",
      "    CA: Demografia? No conec ningú menor de 35 anys que tingui televisió per cable.\n",
      "    Emotions: ['confusion']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[11] EN: Aww... she'll probably come around eventually, I'm sure she was just jealous of [NAME]... I mean, what woman wouldn't be! lol \n",
      "    CA: Aww... ella probablement vindrà per aquí eventualment, estic segur que només estava gelosa de [NOM]... Vull dir, quina dona no seria! lol\n",
      "    Emotions: ['amusement', 'approval']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[12] EN: Hello everyone. Im from Toronto as well. Can call and visit in personal if needed.\n",
      "    CA: Hola a tots. Sóc de Toronto, així. Pot trucar i visitar en personal si és necessari.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[13] EN: R/sleeptrain Might be time for some sleep training. Take a look and try to feel out what's right for your family.\n",
      "    CA: R /sleeptrain Pot ser el moment d'una mica d'entrenament per dormir. Fer una ullada i tractar de sentir el que és adequat per a la seva família.\n",
      "    Emotions: ['caring']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[14] EN: [NAME] - same fucking problem, slightly better command of the English language.\n",
      "    CA: [NOM] - el mateix maleït problema, un domini lleugerament millor de l'idioma anglès.\n",
      "    Emotions: ['annoyance']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[15] EN: Shit, I guess I accidentally bought a Pay-Per-View boxing match\n",
      "    CA: Merda, suposo que accidentalment vaig comprar un fòsfor de boxa Pay-Per-View\n",
      "    Emotions: ['annoyance', 'embarrassment']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[16] EN: Thank you friend\n",
      "    CA: Gràcies amic\n",
      "    Emotions: ['gratitude']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[17] EN: Fucking coward.\n",
      "    CA: Maleït covard.\n",
      "    Emotions: ['anger']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[18] EN: that is what retardation looks like\n",
      "    CA: així és el retard\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[19] EN: Maybe that’s what happened to the great white at Houston zoo\n",
      "    CA: Potser això és el que li va passar al gran blanc al zoo de Houston\n",
      "    Emotions: ['confusion', 'realization']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[20] EN: I never thought it was at the same moment, but sometimes after [NAME] sacrifice... sounds logical\n",
      "    CA: Mai vaig pensar que fos en el mateix moment, però de vegades després de [NOM] sacrifici... sona lògic\n",
      "    Emotions: ['confusion', 'disappointment', 'neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[21] EN: i got a bump and a bald spot. i feel dumb <3\n",
      "    CA: tinc un bony i una calba. em sento ximple <3\n",
      "    Emotions: ['embarrassment']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[22] EN: You are going to do the dishes now\n",
      "    CA: Ara rentaràs els plats\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[23] EN: Slowing things down now\n",
      "    CA: Ara s'estan alentint les coses\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[24] EN: His name has already been released. Just can't post it here.\n",
      "    CA: El seu nom ja ha estat alliberat. No el puc publicar aquí.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[25] EN: Stupidly stubborn / stubbornly stupid\n",
      "    CA: Estúpidament tossut / obstinadament estúpid\n",
      "    Emotions: ['anger']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[26] EN: Mine was apparently [NAME] and the giant peach!\n",
      "    CA: El meu era aparentment [NOM] i el préssec gegant!\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[27] EN: I miss them being alive\n",
      "    CA: Trobo a faltar que estiguin vius\n",
      "    Emotions: ['grief', 'sadness']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[28] EN: Super, thanks\n",
      "    CA: Super, gràcies\n",
      "    Emotions: ['gratitude']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[29] EN: A new study just came out from China that it's actually too late.\n",
      "    CA: Acaba de sortir un nou estudi de la Xina que en realitat és massa tard.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[30] EN: Troll, bro. They know they're saying stupid shit. The motherfucker does nothing but stink up libertarian subs talking shit\n",
      "    CA: Troll, germà. Saben que estan dient ximpleries. El fill de puta no fa res més que fer pudor els subs llibertaris parlant merda\n",
      "    Emotions: ['anger']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[31] EN: All sounds possible except the key, I can't see how it was missed in the first search. \n",
      "    CA: Tots els sons possibles excepte la clau, no puc veure com es va perdre a la primera cerca.\n",
      "    Emotions: ['confusion']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[32] EN: Your aunt has some damn nerve, though!\n",
      "    CA: Però la teva tia té una mica de nervi!\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[33] EN: Ok, then what the actual fuck is your plan?\n",
      "    CA: Ok, llavors quin carall és el teu pla?\n",
      "    Emotions: ['anger', 'curiosity']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[34] EN: What does FPTP have to do with the referendum?\n",
      "    CA: Què té a veure FPTP amb el referèndum?\n",
      "    Emotions: ['confusion']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[35] EN: Happy to be able to help.\n",
      "    CA: Feliç de poder ajudar.\n",
      "    Emotions: ['joy']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[36] EN: 18 is hot but very bland, it's just here this blonde lady who is not as hot as blonde launch.\n",
      "    CA: 18 és calent però molt insípid, només és aquí aquesta senyora rossa que no és tan calenta com rossa llançament.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[37] EN: Famous for his 3-4 Defense\n",
      "    CA: Famós per la seva defensa 3-4\n",
      "    Emotions: ['admiration']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[38] EN: Pretty sure I’ve seen this. He swings away with the harness he is wearing. Still looks painful but I think he lives\n",
      "    CA: Bastant segur que he vist això. Es balanceja amb l'arnès que porta. Encara es veu dolorós, però crec que viu\n",
      "    Emotions: ['sadness']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[39] EN: When I feel down I listen to music.\n",
      "    CA: Quan em sento deprimit escolto música.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[40] EN: aw, thanks! I appreciate that! \n",
      "    CA: aw, gràcies! T'ho agraeixo!\n",
      "    Emotions: ['admiration', 'gratitude']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[41] EN: Thanks! I love watching him every week\n",
      "    CA: Gràcies. M'encanta veure' l cada setmana\n",
      "    Emotions: ['gratitude', 'love']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[42] EN: I read on a different post that he died shortly after of internal injuries.\n",
      "    CA: He llegit en un altre post que va morir poc després per ferides internes.\n",
      "    Emotions: ['grief', 'neutral']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[43] EN: Honestly it sounds exhausting being married to him. Maybe it will be better for you in the long run.\n",
      "    CA: Honestament, sona esgotador estar casat amb ell. Potser serà millor per a tu a llarg termini.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[44] EN: It's crazy how far Photoshop has come. Underwater bridges?!! NEVER!!!\n",
      "    CA: És una bogeria el lluny que ha arribat Photoshop. Ponts submarins?!! MAI!!!\n",
      "    Emotions: ['curiosity', 'excitement']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[45] EN: I wouldn't let a sweet potato dictate decisions, ever.\n",
      "    CA: Jo no deixaria que una batata dictés decisions, mai.\n",
      "    Emotions: ['disapproval']\n",
      "    Sentiment: negative\n",
      "----------\n",
      "[46] EN: It's true though. He either gets no shirt and freezes to death or wears a stupid looking butchers cape. I hope he gets something better next season\n",
      "    CA: És cert, però. O no aconsegueix camisa i es congela fins a la mort o porta una capa de carnisser d'aspecte estúpid. Espero que aconsegueixi alguna cosa millor la temporada que\n",
      "    Emotions: ['optimism']\n",
      "    Sentiment: positive\n",
      "----------\n",
      "[47] EN: It's a better option because it's my life and none of your business? Lmfao, who are you\n",
      "    CA: És una millor opció perquè és la meva vida i no és assumpte teu? Lmfao, qui ets\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[48] EN: Sack, shaft, and tip. The trifecta. \n",
      "    CA: Sac, eix i punta. La trifecta.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[49] EN: I know. My question was if they **used** to compete in T5-TTT2.\n",
      "    CA: Ho sé. La meva pregunta era si **utilitzaven** per competir en T5-TTT2.\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n",
      "[50] EN: FBI!! OPEN UP!!!\n",
      "    CA: FBI!! OBRIR!!!\n",
      "    Emotions: ['neutral']\n",
      "    Sentiment: neutral\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 477.44ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 981.12ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1591.77ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Script finished and files saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "for package in [\"ctranslate2\", \"sentencepiece\", \"kagglehub[hf-datasets]\", \"datasets\", \"tqdm\", \"huggingface_hub\"]:\n",
    "    pkg_name = package.split(\"[\")[0] if \"[\" in package else package\n",
    "    try:\n",
    "        __import__(pkg_name)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from huggingface_hub import snapshot_download\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "import ctranslate2\n",
    "import sentencepiece as spm\n",
    "\n",
    "file_path = \"data/train.tsv\"\n",
    "hf_ds = kagglehub.load_dataset(\n",
    "    KaggleDatasetAdapter.HUGGING_FACE,\n",
    "    \"debarshichanda/goemotions\",\n",
    "    file_path,\n",
    "    pandas_kwargs={\n",
    "        \"sep\": \"\\t\",\n",
    "        \"names\": [\"text_en\", \"labels\", \"id\"],\n",
    "        \"header\": 0\n",
    "    }\n",
    ")\n",
    "hf_ds = hf_ds.remove_columns(\"id\")\n",
    "hf_ds = hf_ds.select(range(10000))\n",
    "\n",
    "model_dir = snapshot_download(repo_id=\"projecte-aina/aina-translator-en-ca\", revision=\"main\")\n",
    "sp_model_path = os.path.join(model_dir, \"spm.model\")\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(sp_model_path)\n",
    "translator = ctranslate2.Translator(model_dir)\n",
    "\n",
    "def translate_en_to_ca(text):\n",
    "    try:\n",
    "        tokens = sp.encode(text, out_type=str)\n",
    "        translation = translator.translate_batch([tokens])\n",
    "        return sp.decode(translation[0][0][\"tokens\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {text[:50]}... → {e}\")\n",
    "        return \"\"\n",
    "\n",
    "tqdm.pandas()\n",
    "df = hf_ds.to_pandas()\n",
    "df[\"text\"] = df[\"text_en\"].progress_apply(translate_en_to_ca)\n",
    "\n",
    "\n",
    "hf_ds = Dataset.from_pandas(df)\n",
    "\n",
    "def parse_labels(labels_str):\n",
    "\n",
    "    if isinstance(labels_str, list):\n",
    "        return labels_str\n",
    "    if isinstance(labels_str, int):\n",
    "        return [labels_str]\n",
    "    \n",
    "    try:\n",
    "        if isinstance(labels_str, str) and labels_str:\n",
    "            return [int(i) for i in labels_str.split(',')]\n",
    "        return []\n",
    "    except (ValueError, TypeError):\n",
    "        return []\n",
    "\n",
    "emotion_id2label = [\n",
    "    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\", \"confusion\",\n",
    "    \"curiosity\", \"desire\", \"disappointment\", \"disapproval\", \"disgust\", \"embarrassment\",\n",
    "    \"excitement\", \"fear\", \"gratitude\", \"grief\", \"joy\", \"love\", \"nervousness\", \"optimism\",\n",
    "    \"pride\", \"realization\", \"relief\", \"remorse\", \"sadness\", \"surprise\", \"neutral\"\n",
    "]\n",
    "\n",
    "sentiment_map = {\n",
    "    \"positive\": {\"amusement\", \"excitement\", \"joy\", \"love\", \"desire\", \"optimism\", \"caring\",\n",
    "                 \"pride\", \"admiration\", \"gratitude\", \"relief\", \"approval\"},\n",
    "    \"negative\": {\"fear\", \"nervousness\", \"remorse\", \"embarrassment\", \"disappointment\",\n",
    "                 \"sadness\", \"grief\", \"disgust\", \"anger\", \"annoyance\", \"disapproval\"},\n",
    "    \"ambiguous\": {\"realization\", \"surprise\", \"curiosity\", \"confusion\"}\n",
    "}\n",
    "\n",
    "def classify_sentiment(emotion_ids):\n",
    "    \"\"\"Clasifica el sentimiento basado en una lista de IDs de emoción.\"\"\"\n",
    "    counts = {\"positive\": 0, \"negative\": 0, \"ambiguous\": 0}\n",
    "\n",
    "    for eid in emotion_ids:\n",
    "        if isinstance(eid, int) and eid < len(emotion_id2label):\n",
    "            emotion = emotion_id2label[eid]\n",
    "            for category in sentiment_map:\n",
    "                if emotion in sentiment_map[category]:\n",
    "                    counts[category] += 1\n",
    "                    break\n",
    "    if counts[\"positive\"] > counts[\"negative\"] and counts[\"positive\"] > counts[\"ambiguous\"]:\n",
    "        return \"positive\"\n",
    "    elif counts[\"negative\"] > counts[\"positive\"] and counts[\"negative\"] > counts[\"ambiguous\"]:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "def process_and_classify(example):\n",
    "    parsed_labels = parse_labels(example[\"labels\"])\n",
    "    return {\n",
    "        \"labels\": parsed_labels,\n",
    "        \"label\": classify_sentiment(parsed_labels)\n",
    "    }\n",
    "\n",
    "hf_ds = hf_ds.map(process_and_classify)\n",
    "\n",
    "print(\"\\nExample samples:\\n\")\n",
    "for i in range(50):\n",
    "    row = hf_ds[i]\n",
    "    emotions = [emotion_id2label[e] for e in row[\"labels\"]]\n",
    "    print(f\"[{i+1}] EN: {row['text_en']}\")\n",
    "    print(f\"    CA: {row['text']}\")\n",
    "    print(f\"    Emotions: {emotions}\")\n",
    "    print(f\"    Sentiment: {row['label']}\")\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "hf_ds = hf_ds.remove_columns([\"labels\", \"text_en\"])\n",
    "ds_split = hf_ds.train_test_split(test_size=0.2, seed=42)\n",
    "ds_val_test = ds_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "ds_goemotions_clean = {\n",
    "    \"train\": ds_split[\"train\"],\n",
    "    \"validation\": ds_val_test[\"train\"],\n",
    "    \"test\": ds_val_test[\"test\"]\n",
    "}\n",
    "\n",
    "for split in ds_goemotions_clean:\n",
    "    keep = [\"text\", \"label\"]\n",
    "    drop = [col for col in ds_goemotions_clean[split].column_names if col not in keep]\n",
    "    ds_goemotions_clean[split] = ds_goemotions_clean[split].remove_columns(drop)\n",
    "\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    os.makedirs(split, exist_ok=True)\n",
    "    output_path = os.path.join(split, \"goemotions.csv\")\n",
    "    ds_goemotions_clean[split].to_csv(output_path, index=False)\n",
    "\n",
    "print(\"\\nScript finished and files saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b390fba",
   "metadata": {},
   "source": [
    "## 4. Create the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ff359d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 'train' folder with 3 CSV files...\n",
      "Saved combined CSV to: /home/user/Escritorio/TFM/train/train.csv\n",
      "\n",
      "Processing 'validation' folder with 3 CSV files...\n",
      "Saved combined CSV to: /home/user/Escritorio/TFM/validation/validation.csv\n",
      "\n",
      "Processing 'test' folder with 3 CSV files...\n",
      "Saved combined CSV to: /home/user/Escritorio/TFM/test/test.csv\n",
      "\n",
      "Final dataset row counts:\n",
      "- train: 9950 rows\n",
      "- validation: 1150 rows\n",
      "- test: 1150 rows\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "splits = [\"train\", \"validation\", \"test\"]\n",
    "expected_columns = [\"text\", \"label\"]\n",
    "row_counts = {}\n",
    "\n",
    "for split in splits:\n",
    "    folder_path = os.path.abspath(split)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    all_csvs = [os.path.join(folder_path, f) for f in os.listdir(folder_path)\n",
    "                if f.endswith(\".csv\") and f != f\"{split}.csv\"]  # Skip previous output if re-run\n",
    "\n",
    "    if not all_csvs:\n",
    "        print(f\"No CSV files found in: {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing '{split}' folder with {len(all_csvs)} CSV files...\")\n",
    "\n",
    "    dfs = []\n",
    "    for csv_file in all_csvs:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            if set(df.columns) != set(expected_columns):\n",
    "                print(f\"Skipping {csv_file} (columns mismatch: found {list(df.columns)})\")\n",
    "                continue\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {csv_file}: {e}\")\n",
    "\n",
    "    if dfs:\n",
    "        combined = pd.concat(dfs, ignore_index=True)\n",
    "        row_counts[split] = len(combined)\n",
    "\n",
    "        output_path = os.path.join(folder_path, f\"{split}.csv\")\n",
    "        combined.to_csv(output_path, index=False)\n",
    "        print(f\"Saved combined CSV to: {output_path}\")\n",
    "    else:\n",
    "        print(f\"No valid CSV files to combine in: {folder_path}\")\n",
    "        row_counts[split] = 0\n",
    "\n",
    "\n",
    "print(\"\\nFinal dataset row counts:\")\n",
    "for split in splits:\n",
    "    print(f\"- {split}: {row_counts.get(split, 0)} rows\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
